[{"id":"53863MIT67122","language":"en","level":"Intermediate to advanced","title":"Vibe Analytics: Vibe Coding’s New Cousin Unlocks Insights","authors":["Michael Schrage"],"pages":"8","publication_date":"July 2025","description":"Traditional data analysis looks like this: Define questions; structure queries; execute models; visualize results. Vibe analytics collapses this chain into an improvisational dialogue with data using generative AI tools, much like vibe coding transforms programming. Instead of waiting for data scientists to produce insights, leaders can engage directly with data sets through conversation — and get insights quickly. Find out how companies have already used this approach and learn what’s required.","tags":["Data","Data Science","Data Science Tasks","Exploratory Data Analysis"]},{"id":"9781633435896","language":"en","level":"Intermediate to advanced","title":"Time Series Forecasting Using Foundation Models","authors":["Marco Peixeiro"],"pages":"256","publication_date":"November 2025","description":"Make accurate time series predictions with powerful pretrained foundation models! You don’t need to spend weeks—or even months—coding and training your own models for time series forecasting. Time Series Forecasting Using Foundation Models shows you how to make accurate predictions using flexible pretrained models. In Time Series Forecasting Using Foundation Models you will discover:\nThe inner workings of large time models\nZero-shot forecasting on custom datasets\nFine-tuning foundation forecasting models\nEvaluating large time models\nTime Series Forecasting Using Foundation Models teaches you how to do efficient forecasting using powerful time series models that have already been pretrained on billions of data points. You’ll appreciate the hands-on examples that show you what you can accomplish with these amazing models. Along the way, you’ll learn how time series foundation models work, how to fine-tune them, and how to use them with your own data.About the TechnologyTime-series forecasting is the art of analyzing historical, time-stamped data to predict future outcomes. Foundational time series models like TimeGPT and Chronos, pre-trained on billions of data points, can now effectively augment or replace painstakingly-built custom time-series models.About the BookTime Series Forecasting Using Foundation Models explores the architecture of large time models and shows you how to use them to generate fast, accurate predictions. You’ll learn to fine-tune time models on your own data, execute zero-shot probabilistic forecasting, point forecasting, and more. You’ll even find out how to reprogram an LLM into a time series forecaster—all following examples that will run on an ordinary laptop.What's Inside\nHow large time models work\nZero-shot forecasting on custom datasets\nFine-tuning and evaluating foundation models\nAbout the ReaderFor data scientists and machine learning engineers familiar with the basics of time series forecasting theory. Examples in Python.About the AuthorMarco Peixeiro builds cutting-edge open-source forecasting Python libraries at Nixtla. He is the author of Time Series Forecasting in Python.QuotesClear and hands-on, featuring both theory and easy-to-follow examples.- Eryk Lewinson, Author of Python for Finance CookbookBridges the gap between classical forecasting methods and the new developments in the foundational models. A fantastic resource.- Juan Orduz, PyMC LabsA foundational guide to forecasting’s next chapter.- Tyler Blume, daybreakAn immensely practical introduction to forecasting using foundation models.- Stephan Kolassa, SAP Switzerland","tags":["Data","Data Science","Data Science Tasks","Statistics","Time Series"]},{"id":"9781617296901","language":"en","level":"Beginner to intermediate","title":"Data Pipelines with Apache Airflow","authors":["Julian de Ruiter","Bas Harenslak"],"pages":"star rating fill","publication_date":"May 2021","description":"A successful pipeline moves data efficiently, minimizing pauses and blockages between tasks, keeping every process along the way operational. Apache Airflow provides a single customizable environment for building and managing data pipelines, eliminating the need for a hodgepodge collection of tools, snowflake code, and homegrown processes. Using real-world scenarios and examples, Data Pipelines with Apache Airflow teaches you how to simplify and automate data pipelines, reduce operational overhead, and smoothly integrate all the technologies in your stack.About the TechnologyData pipelines manage the flow of data from initial collection through consolidation, cleaning, analysis, visualization, and more. Apache Airflow provides a single platform you can use to design, implement, monitor, and maintain your pipelines. Its easy-to-use UI, plug-and-play options, and flexible Python scripting make Airflow perfect for any data management task.About the BookData Pipelines with Apache Airflow teaches you how to build and maintain effective data pipelines. You’ll explore the most common usage patterns, including aggregating multiple data sources, connecting to and from data lakes, and cloud deployment. Part reference and part tutorial, this practical guide covers every aspect of the directed acyclic graphs (DAGs) that power Airflow, and how to customize them for your pipeline’s needs.What's Inside\nBuild, test, and deploy Airflow pipelines as DAGs\nAutomate moving and transforming data\nAnalyze historical datasets using backfilling\nDevelop custom components\nSet up Airflow in production environments\nAbout the ReaderFor DevOps, data engineers, machine learning engineers, and sysadmins with intermediate Python skills.About the AuthorsBas Harenslak and Julian de Ruiter are data engineers with extensive experience using Airflow to develop pipelines for major companies. Bas is also an Airflow committer.QuotesAn Airflow bible. Useful for all kinds of users, from novice to expert.- Rambabu Posa, Sai Aashika ConsultancyAn easy-to-follow exploration of the benefits of orchestrating your data pipeline jobs with Airflow.- Daniel Lamblin, CoupangThe one reference you need to create, author, schedule, and monitor workflows with Apache Airflow. Clear recommendation.- Thorsten Weber, bbv Software Services AGBy far the best resource for Airflow.- Jonathan Wood, LexisNexis","tags":["Data","Data Engineering","Apache Airflow"]},{"id":"9781835468531","language":"en","level":"Intermediate to advanced","title":"Managing Data as a Product","authors":["Andrea Gioia"],"pages":"star rating fill","publication_date":"November 2024","description":"Discover how to transform your data architecture with the insights and techniques presented in Managing Data as a Product by Andrea Gioia. In this comprehensive guide, you'll explore how to design, implement, and maintain data-product-centered systems to meet modern demands, achieving scalable and sustainable data management tailored to your organization's needs.\n\nWhat this Book will help me do\n\nUnderstand the principles of data-product-centered architectures and their advantages.\nLearn to design, develop, and operate data products in production settings.\nExplore strategies to manage the lifecycle of data products efficiently.\nGain insights into team topologies and data ownership for distributed systems.\nDiscover data modeling techniques for AI-ready architectures.\n\nAuthor(s)\n\nAndrea Gioia is a renowned data architect and the creator of the Open Data Mesh Initiative. With over 20 years of experience, Andrea has successfully led complex data projects and is passionate about sharing his expertise. His writing is practical and driven by real-world challenges, aiming to equip engineers with actionable knowledge.\n\nWho is it for?\n\nThis book is ideal for data engineers, software architects, and engineering leaders involved in shaping innovative data architectures. If you have foundational knowledge of data engineering and are eager to advance your expertise by adopting data-product principles, this book will suit your needs. It is for professionals aiming to modernize and optimize their approach to organizational data management.","tags":["Data","Data Engineering"]},{"id":"9780128026489","language":"en","level":"Beginner to intermediate","title":"Building a Scalable Data Warehouse with Data Vault 2.0","authors":["Daniel Linstedt","Michael Olschimke"],"pages":"star rating fill","publication_date":"September 2015","description":"The Data Vault was invented by Dan Linstedt at the U.S. Department of Defense, and the standard has been successfully applied to data warehousing projects at organizations of different sizes, from small to large-size corporations. Due to its simplified design, which is adapted from nature, the Data Vault 2.0 standard helps prevent typical data warehousing failures.\n\n\"Building a Scalable Data Warehouse\" covers everything one needs to know to create a scalable data warehouse end to end, including a presentation of the Data Vault modeling technique, which provides the foundations to create a technical data warehouse layer. The book discusses how to build the data warehouse incrementally using the agile Data Vault 2.0 methodology. In addition, readers will learn how to create the input layer (the stage layer) and the presentation layer (data mart) of the Data Vault 2.0 architecture including implementation best practices. Drawing upon years of practical experience and using numerous examples and an easy to understand framework, Dan Linstedt and Michael Olschimke discuss:\n\nHow to load each layer using SQL Server Integration Services (SSIS), including automation of the Data Vault loading processes.\n\nImportant data warehouse technologies and practices.\n\nData Quality Services (DQS) and Master Data Services (MDS) in the context of the Data Vault architecture.\nProvides a complete introduction to data warehousing, applications, and the business context so readers can get-up and running fast\nExplains theoretical concepts and provides hands-on instruction on how to build and implement a data warehouse\nDemystifies data vault modeling with beginning, intermediate, and advanced techniques\nDiscusses the advantages of the data vault approach over other techniques, also including the latest updates to Data Vault 2.0 and multiple improvements to Data Vault 1.0","tags":["Data","Data Engineering","Storage Repositories","Data Warehouse"]},{"id":"9798888650011","language":"en","level":"Intermediate to advanced","title":"SQL Antipatterns, Volume 1","authors":["Bill Karwin"],"pages":"star rating fill","publication_date":"October 2022","description":"SQL is the ubiquitous language for software developers working with structured data. Most developers who rely on SQL are experts in their favorite language (such as Java, Python, or Go), but they're not experts in SQL. They often depend on antipatterns - solutions that look right but become increasingly painful to work with as you uncover their hidden costs. Learn to identify and avoid many of these common blunders. Refactor an inherited nightmare into a data model that really works. Updated for the current versions of MySQL and Python, this new edition adds a dozen brand new mini-antipatterns for quick wins.\n\nNo matter which platform, framework, or language you use, the database is the foundation of your application, and the SQL database language is the standard for working with it. Antipatterns are solutions that look simple at the surface, but soon mire you down with needless work. Learn to identify these traps, and craft better solutions for the often-asked questions in this book. Avoid the mistakes that lead to poor performance and quality, and master the principles that make SQL a powerful and flexible tool for handling data and logic.\n\nDive deep into SQL and database design, and learn to recognize the most common missteps made by software developers in database modeling, SQL query logic, and code design of data-driven applications. See practical examples of misconceptions about SQL that can lure software projects astray. Find the greatest value in each group of data. Understand why an intersection table may be your new best friend. Store passwords securely and don't reinvent the wheel. Handle NULL values like a pro. Defend your web applications against the security weakness of SQL injection.\n\nUse SQL the right way - it can save you from headaches and needless work, and let your application really shine!\n\nWhat You Need:\n\nThe SQL examples use the MySQL 8.0 flavor, but other popular brands of RDBMS are mentioned. Other code examples use Python 3.9+ or Ruby 2.7+.","tags":["Data","Data Engineering","SQL"]},{"id":"9781492085911","language":"en","level":"Beginner","title":"Learning MySQL, 2nd Edition","authors":["Vinicius M. Grippa","Sergey Kuzmichev"],"pages":"star rating fill","publication_date":"September 2021","description":"Get a comprehensive overview on how to set up and design an effective database with MySQL. This thoroughly updated edition covers MySQL's latest version, including its most important aspects. Whether you're deploying an environment, troubleshooting an issue, or engaging in disaster recovery, this practical guide provides the insights and tools necessary to take full advantage of this powerful RDBMS.\n\nAuthors Vinicius Grippa and Sergey Kuzmichev from Percona show developers and DBAs methods for minimizing costs and maximizing availability and performance. You'll learn how to perform basic and advanced querying, monitoring and troubleshooting, database management and security, backup and recovery, and tuning for improved efficiency. This edition includes new chapters on high availability, load balancing, and using MySQL in the cloud.\n\nGet started with MySQL and learn how to use it in production\nDeploy MySQL databases on bare metal, on virtual machines, and in the cloud\nDesign database infrastructures\nCode highly efficient queries\nMonitor and troubleshoot MySQL databases\nExecute efficient backup and restore operations\nOptimize database costs in the cloud\nUnderstand database concepts, especially those pertaining to MySQL","tags":["Data","Data Engineering","Relational Databases","MySQL"]},{"id":"9781803248226","language":"en","level":"Intermediate to advanced","title":"Streamlit for Data Science - Second Edition","authors":["Tyler Richards"],"pages":"star rating fill","publication_date":"September 2023","description":"Streamlit for Data Science is your complete guide to mastering the creation of powerful, interactive data-driven applications using Python and Streamlit. With this comprehensive resource, you'll learn everything from foundational Streamlit skills to advanced techniques like integrating machine learning models and deploying apps to cloud platforms, enabling you to significantly enhance your data science toolkit.\n\nWhat this Book will help me do\n\nMaster building interactive applications using Streamlit, including techniques for user interfaces and integrations.\nDevelop visually appealing and functional data visualizations using Python libraries in Streamlit.\nLearn to integrate Streamlit applications with machine learning frameworks and tools like Hugging Face and OpenAI.\nUnderstand and apply best practices to deploy Streamlit apps to cloud platforms such as Streamlit Community Cloud and Heroku.\nImprove practical Python skills through implementing end-to-end data applications and prototyping data workflows.\n\nAuthor(s)\n\nTyler Richards, the author of Streamlit for Data Science, is a senior data scientist with in-depth practical experience in building data-driven applications. With a passion for Python and data visualization, Tyler leverages his knowledge to help data professionals craft effective and compelling tools. His teaching approach combines clarity, hands-on exercises, and practical relevance.\n\nWho is it for?\n\nThis book is written for data scientists, engineers, and enthusiasts who use Python and want to create dynamic data-driven applications. With a focus on those who have some familiarity with Python and libraries like Pandas or NumPy, it assists readers in building on their knowledge by offering tailored guidance. Perfect for those looking to prototype data projects or enhance their programming toolkit.","tags":["Data","Data Science"]},{"id":"9781837636594","language":"en","level":"Intermediate to advanced","title":"Data Stewardship in Action","authors":["Pui Shing Lee"],"pages":"272","publication_date":"February 2024","description":"Unleash the potential of data in your organization with 'Data Stewardship in Action.' This book takes you through the journey of understanding and implementing data stewardship practices that drive measurable business value. By mastering these skills, you'll be able to build robust data governance frameworks and strategies that enable your team to make informed, data-driven decisions.\n\nWhat this Book will help me do\n\nLearn how to effectively become a data steward and understand the scope of responsibilities.\nGain practical knowledge in building a data strategy and converting it into a data operational model.\nDevelop practical skills in setting up and running a data stewardship program.\nUnderstand how to use best practices to implement data governance frameworks.\nMaster tools and techniques for elevating organizational data management maturity.\n\nAuthor(s)\n\nPui Shing Lee is a renowned expert in data governance and stewardship with years of experience in the field. Lee focuses on the practical implementation of data strategies and frameworks, ensuring real-life applicability. Through their work, they have helped numerous organizations enhance their data maturity and achieve measurable business results. Their writing merges technical expertise with engaging and approachable instruction.\n\nWho is it for?\n\nThis book is tailored for professionals in data management looking to refine their skills, such as analysts, engineers, and scientists. Senior executives aiming to establish or revamp data governance structures will also find it highly beneficial. While accessible to beginners, foundational knowledge of data management concepts is recommended to fully benefit from the content. Ideal for anyone aiming to elevate their expertise in organizational data management.","tags":["Data","Data Governance"]},{"id":"9798341607736","language":"en","level":"Beginner","title":"Head First Statistics for Data Analysis","authors":["Dawn Griffiths"],"publication_date":"July 2027","description":"What will you learn from this book?\n\nDo you need to analyze data but feel lost in a sea of numbers? Your guide is here—without the dry, academic jargon. This hands-on, visually rich book introduces key statistical concepts and shows you how to apply them using Excel. Whether you're a data analyst, a business professional, or just someone who wants to make better decisions with data, you'll gain the practical skills needed to extract meaningful insights. From probability and confidence intervals to regression and forecasting, this book makes statistics approachable, relevant, and—even better—understandable.\n\nWhat's so special about this book?\n\nIf you've read a Head First book before, you know what to expect: a uniquely engaging, brain-friendly approach that helps you truly learn instead of struggling through dense theory. Through clear explanations, hands-on exercises, and interactive visuals, you'll develop the skills to confidently analyze data and make informed decisions. No more guesswork—just real statistical insights at your fingertips.","tags":["Data","Data Science","Data Science Tasks","Statistics"]},{"id":"9780764567575","language":"en","level":"Beginner to intermediate","title":"The Data Warehouse ETL Toolkit: Practical Techniques for Extracting, Cleaning, Conforming, and Delivering Data","authors":["Ralph Kimball","Joe Caserta"],"pages":"star rating fill","publication_date":"October 2004","description":"Cowritten by Ralph Kimball, the world's leading data warehousing authority, whose previous books have sold more than 150,000 copies\n\nDelivers real-world solutions for the most time- and labor-intensive portion of data warehousing-data staging, or the extract, transform, load (ETL) process\n\nDelineates best practices for extracting data from scattered sources, removing redundant and inaccurate data, transforming the remaining data into correctly formatted data structures, and then loading the end product into the data warehouse\n\nOffers proven time-saving ETL techniques, comprehensive guidance on building dimensional structures, and crucial advice on ensuring data quality","tags":["Data","Data Engineering"]},{"id":"9798868809385","language":"en","level":"Intermediate to advanced","title":"Snowflake Recipes: A Problem-Solution Approach to Implementing Modern Data Pipelines","authors":["Dillon Dayton","John Eipe"],"pages":"413","publication_date":"December 2024","description":"Explore Snowflake’s core concepts and unique features that differentiates it from industry competitors, such as, Azure Synapse and Google BigQuery. This book provides recipes for architecting and developing modern data pipelines on the Snowflake data platform by employing progressive techniques, agile practices, and repeatable strategies.\n\nYou’ll walk through step-by-step instructions on ready-to-use recipes covering a wide range of the latest development topics.  Then build scalable development pipelines and solve specific scenarios common to all modern data platforms, such as, data masking, object tagging, data monetization, and security best practices. Throughout the book you’ll work with code samples for Amazon Web Services, Microsoft Azure, and Google Cloud Platform. There’s also a chapter devoted to solving machine learning problems with Snowflake.\n\nAuthors Dillon Dayton and John Eipe are both Snowflake SnowPro Core certified, specializing in data and digital services, and understand the challenges of finding the right solution to complex problems. The recipes in this book are based on real world use cases and examples designed to help you provide quality, performant, and secured data to solve business initiatives.\n\nWhat You’ll Learn\n\nHandle structured and un- structured data in Snowflake.\nApply best practices and different options for data transformation.\nUnderstand data application development. \nImplement data sharing, data governance and security.\n\nWho This book Is For\n\nData engineers, scientists and analysts moving into Snowflake, looking to build data apps. This book expects basic knowledge in Cloud (AWS or Azure or GCP), SQL and Python","tags":["Data","Data Engineering","Snowflake"]},{"id":"9781787288942","language":"en","level":"Beginner to intermediate","title":"Mastering SAP ABAP","authors":["Pawe≈Ç Grze≈õkowiak","Philipp Deth","Wojciech Ciesielski"],"pages":"548","publication_date":"May 2019","description":"Mastering SAP ABAP guides you through learning and applying the powerful SAP ABAP programming language. You will start with foundational concepts of programming within SAP environments and progress towards advanced topics such as UI development with SAPUI5 and optimizing ABAP code performance.\n\nWhat this Book will help me do\n\nMaster the ABAP programming language, from fundamental constructs to advanced techniques.\nLearn to design and implement efficient and maintainable SAP applications.\nGain expertise in creating modern UIs for SAP systems using SAPUI5.\nUnderstand performance optimization techniques for SAP ABAP programs.\nAcquire skills to handle exceptions and perform robust testing in ABAP.\n\nAuthor(s)\n\nThe authors, Paweł Grzełkowiak, Philipp Deth, Wojciech Ciesielski, and Wojciech Łuźwik, are seasoned SAP technologists with years of practical experience in development and consulting. Their dedication to clarity and usefulness is evident in this book, where they share their collective expertise.\n\nWho is it for?\n\nThis book is for SAP developers, both budding and experienced, who want to increase their efficiency in ABAP programming. Prior exposure to programming concepts and a desire to understand SAP-specific technologies are required prerequisites. Whether you are delving deeper into your career as an SAP developer or are aiming to bring new technical solutions to your organization, this guide is ideal for you.","tags":["Data","Data Engineering","SAP"]},{"id":"9798868809804","language":"en","level":"Intermediate to advanced","title":"Hacking MySQL: Breaking, Optimizing, and Securing MySQL for Your Use Case","authors":["Lukas Vileikis"],"pages":"382","publication_date":"December 2024","description":"Your MySQL instances are probably broken. Many developers face slow-running queries, issues related to database architecture, replication, or database security—and that’s only the beginning. This book will deliver answers to your most pressing MySQL database questions related to performance, availability, or security by uncovering what causes databases to break in the first place.\n\nAt its core, this book provides you with the knowledge necessary for you to break your database instances so you can better optimize it for performance and secure it from data breaches. In other words, you’ll discover the sorts of actions, minor and major, that degrade databases so you can fix and ultimately preempt them. MySQL sometimes acts according to its own rules, and this book will help you keep it working on your terms. At the same time, you will learn to optimize your backup and recovery procedures, determine when and which data to index to achieve maximum performance, and choose the best MySQL configurations, among other essential skills.\n\nMost MySQL books focus exclusively on optimization, but this book argues that it’s just as important to pay attention to the ways databases break. Indeed, after reading this book, you will be able to safely break your database instances to expose and overcome the nuanced issues that affect performance, availability, and security.\n\n \n\nWhat You Will Learn\n\nKnow the basics of MySQL and the storage engines innoDB and MyISAM\nSpot the ways you are harming your database’s performance, availability and security without even realizing it\nFix minor bugs and issues that have surprisingly serious impact\nOptimize schema, data types, queries, indexes, and partitions to head off issues\nUnderstand key MySQL security strategies\n\n \n\nWho This Book Is For\n\nDatabase administrators, web developers, systems administrators, and security professionals with an intermediary knowledge of database management systems and building applications in MySQL","tags":["Data","Data Engineering","Relational Databases","MySQL"]},{"id":"9798868814662","language":"en","level":"Intermediate to advanced","title":"The SAP S/4HANA Handbook for EPC Projects: An End-to-End Solution for the Engineering, Construction and Operations (EC&O) Industry","authors":["Sohail Ahmed"],"pages":"409","publication_date":"July 2025","description":"The SAP S/4HANA Handbook for EPC Projects equips you with the knowledge and insights needed to successfully manage and execute complex Engineering, Procurement, and Construction (EPC) projects using the power of SAP S/4HANA. \n\nBuilding upon your existing knowledge of SAP solutions, this handbook provides advanced insights into EPC project management and addresses the operational challenges unique to the Engineering, Construction and Operations (EC&O) industry by connecting business processes with relevant SAP solutions. It is an essential guide enabling you to gain a deeper understanding of optimizing your project management capabilities using SAP S/4HANA. Whether you are an SAP Solution Architect in Finance, Human Resources, or Supply Chain Management, or a project manager in the EC&O industry, this book  will help you understand how projects can be managed with SAP. \n\nWe begin by examining the world of EPC, EPC/M (Engineering, Procurement, Construction, and Management), and ETO (Engineer-To-Order) projects.Looking at detailed planning, controlling, and execution solutions of EPC projects with S/4HANA Project System, CPM (Commercial Project Management), PPM (Project & Portfolio Management), S/4HANA Add-ons, SAP Cloud Solutions, and to  integrate these with other engineering and project management software such as Tekla and Primavera through SAP BTP (Business Technology Platform).\n\nYou will follow a construction company secure an EPC contract of a refinery upgrade project and demonstrates how SAP is used at every step of the way, from bidding to project closure. Through real-world use-cases, supported by tables and visual aids, you will find the practical solutions offered by SAP S/4HANA.\n\nThe SAP S/4HANA Handbook for EPC Projects is the ultimate resource bridging theory with practical applications, offering a framework to navigate the complexities of modern project management in the EC&O industry.\n\nYou Will Learn To:\n\nUnderstand project management processes with business use cases and their application in SAP\nApply detailed planning, scheduling, resource and management strategies, as well as for risk and claim managmement in large-scale projects.\nMaster project procurement, ETO manufacturing for projects, product and service quality management and the handling of project materials, tools and equipment.\nManage  the design and creation of documentation and oversee change management in EPC projects.\n\nThis Book is For:\n\nProject and Portfolio Managers, SAP Solution Architects and other SAP partners looking for hands-on solutions for the EC&O industry.\nEngineering and Construction Contractors, Engineering Consultants, and Project Management Services companies seeking business transformation with SAP tools and practices","tags":["Data","Data Engineering","SAP"]},{"id":"9780122205316","language":"en","level":"Intermediate to advanced","title":"SQL","authors":["Michael J. Donahoo","Gregory D. Speegle"],"pages":"272","publication_date":"July 2010","description":"SQL is a solid guide and reference to the key elements of SQL and how to use it effectively. Developed by authors who needed a good resource for students in their database class, this is an ideal supplement for database courses — no matter what main text you use or what flavor of SQL is required.\n\nIt features a short and inexpensive introduction to SQL for students who have some programming experience and need to learn the main features of SQL; and suggested shortcuts for learning and practice, depending on the experience of the user.\n\nThis book is recommended for novice developers, programmers, and database administrators as well as students in database courses, business courses, and IT-related courses.\n\nProvides tutorial-based instruction for the main features of SQL for programmers and other technical professionals in need of a brief but really good introduction to SQL.\nThe approach is vendor-neutral—so very adaptable and flexible\nThe focus is on teaching concepts by walking through concrete examples and explanations, and self-review exercises are included at the end of each chapter.\nCoverage is on the key features of the language that are required to understand SQL and begin using it effectively.\nSQL 2003-compliant.","tags":["Data","Data Engineering","Relational Databases","SQLite"]},{"id":"0789736292","language":"en","level":"Beginner to intermediate","title":"Internet Yellow Pages, 2007 Edition","authors":["Mikal E. Belicove","Joe Kraynak"],"pages":"star rating fill","publication_date":"October 2006","description":"Plug Yourself In with\n\nthe Ultimate Guide to\n\nthe Internet!\n\nEXHAUSTIVE INDEX:\n\nAn exhaustive index with thorough\n\ncross-references helps you find exactly what you want, quickly and easily.\n\nINTERNATIONAL COVERAGE:\n\nInternational coverage makes your\n\ndiscoveries on the Web virtually limitless.\n\nSEARCH SECRETS:\n\nMichael Miller, along with Mikal Belicove and Joe Kraynak, have written the foreward that gets you up to speed on searching the Internet, blocking pop-up ads, protecting children online, accessing the wireless Web, plugging in to podcasts and webcasts, and reading fascinating weblogs (blogs).\n\nUse This Complete Guide to Web Surfing at Its Best:\n\n•    Find new job opportunities\n\n•    Find information and resources on\n\nall aspects of adoption\n\n•    Download music from your favorite artists\n\n•    Get tips, strategies, and information\n\non improving your poker game\n\n•    Get free technical support for your\n\nPC or Mac\n\n•    Learn the ancient Chinese art of\n\nFeng Shui\n\n•    Find sites devoted to men’s and\n\nwomen’s health and related issues\n\nCategory Internet–Directories\n\nCovers    The Internet and the World Wide Web\n\nUser Level    All\n\nIn this Edition\n\nIcons identify unique information about\n\neach listed website\n\nBEST OF THE BEST\n\nThis icon identifies THE best website in any given category. If you have time to visit only one site in a category, look for the Best of the Best!\n\nKID ICON\n\nThe child-rating icon is designed to help you weed out sites that are inappropriate for children.\n\nBLOG ICON\n\nThe blog icon identifies those sites that allow\n\nvisitors to post comments and are interactive.\n\nPODCAST\n\nThe Podcast icon identifies sites that provide\n\naudio-on-the-go content.\n\nWEBCAST\n\nThe webcast icon identifies those sites that feature dynamic audio-visual content\n\nRSS FEED ICON \n\nThe RSS Feed icon indicates, quickly and easily, those sites that offer live feeds in any given category.\n\nDIRECTORY ICON\n\nThe Directory icon indicates websites that may not provide a lot of quality information on their own but instead point you to the best sites that deal with a particular topic.\n\nQUALITY INDICATOR\n\nThe quality indicator icon rates sites on a scale of\n\n1 to 5 based on content, appearance, and ease of\n\nuse. Look for a ranking of 5 and you’ve found the most user-friendly sites.\n\n789736292\n\n100307","tags":["Data","Data Engineering","Search"]},{"id":"9780128047460","language":"en","level":"Intermediate to advanced","title":"Mobile Security and Privacy","authors":["Man Ho Au","Raymond Choo"],"pages":"274","publication_date":"September 2016","description":"Mobile Security and Privacy: Advances, Challenges and Future Research Directions provides the first truly holistic view of leading edge mobile security research from Dr. Man Ho Au and Dr. Raymond Choo—leading researchers in mobile security. Mobile devices and apps have become part of everyday life in both developed and developing countries. As with most evolving technologies, mobile devices and mobile apps can be used for criminal exploitation. Along with the increased use of mobile devices and apps to access and store sensitive, personally identifiable information (PII) has come an increasing need for the community to have a better understanding of the associated security and privacy risks.\n\nDrawing upon the expertise of world-renowned researchers and experts, this volume comprehensively discusses a range of mobile security and privacy topics from research, applied, and international perspectives, while aligning technical security implementations with the most recent developments in government, legal, and international environments. The book does not focus on vendor-specific solutions, instead providing a complete presentation of forward-looking research in all areas of mobile security.\n\nThe book will enable practitioners to learn about upcoming trends, scientists to share new directions in research, and government and industry decision-makers to prepare for major strategic decisions regarding implementation of mobile technology security and privacy. In addition to the state-of-the-art research advances, this book also discusses prospective future research topics and open challenges.\n\nPresents the most current and leading edge research on mobile security and privacy, featuring a panel of top experts in the field\nProvides a strategic and international overview of the security issues surrounding mobile technologies\nCovers key technical topics and provides readers with a complete understanding of the most current research findings along with future research directions and challenges\nEnables practitioners to learn about upcoming trends, scientists to share new directions in research, and government and industry decision-makers to prepare for major strategic decisions regarding the implementation of mobile technology security and privacy initiatives","tags":["Data","Data Engineering","Data Security & Privacy"]},{"id":"0642572051754","language":"en","level":"Intermediate","title":"Introduction to Power Query in Excel","authors":["George Mount"],"publication_date":"June 2024","description":"This series focuses on efficient data cleaning techniques crucial for analysts in various sectors. It teaches methods to automate and streamline data preparation, addressing challenges like merging sources and enhancing data quality, empowering viewers with new data management skills.","tags":["Data","Data Science","Data Science Tasks","Data Wrangling, Preparation, Cleaning"]},{"id":"9781788997423","language":"en","level":"Beginner to intermediate","title":"Learn QGIS - Fourth Edition","authors":["Andrew Cutts","Anita Graser"],"pages":"272","publication_date":"November 2018","description":"Unlock the world of geospatial analysis and mapping with 'Learn QGIS.' This comprehensive guide takes you through the capabilities of QGIS 3.4, covering everything from data loading and styling to spatial analysis and plugin development. Geared towards beginners and seasoned GIS users alike, you'll gain hands-on expertise to master QGIS effectively and confidently.\n\nWhat this Book will help me do\n\nLoad, edit, and manage geospatial data efficiently in QGIS 3.4 for impactful analysis.\nCreate professional-grade maps with custom styling and data visualization techniques.\nDelve into the QGIS 3.4 processing toolbox, enhancing analysis workflows.\nBuild bespoke QGIS plugins using Python and QT Designer for tailored solutions.\nUse QGIS 3.4's advanced features like 3D views and GeoPackage efficiently.\n\nAuthor(s)\n\nNone Cutts and Anita Graser bring their extensive technical expertise to 'Learn QGIS.' None Cutts has a background in geospatial technologies and a focus on practical GIS applications. Anita Graser is a recognized QGIS expert, experienced in both software development and geospatial analysis. Together, they share their knowledge in an accessible style, ensuring readers of different levels can benefit.\n\nWho is it for?\n\nThis book is ideal for developers, consultants, or GIS enthusiasts who want to expand their skills in using QGIS 3.4 for geospatial data analysis and mapping. Beginners looking to understand core QGIS capabilities will also find value. If you're aiming to develop professional maps and customize QGIS, this is the resource for you.","tags":["Data","Data Engineering","Location Data","Geographic Information System (GIS)"]},{"id":"9781484299661","language":"en","level":"Beginner to intermediate","title":"Building a Data Culture: The Usage and Flow Data Culture Model","authors":["Gary W. Griffin","David Holcomb"],"pages":"235","publication_date":"November 2023","description":"In today's fast-paced digital landscape, organizations face an ever-increasing volume of data that holds immense potential for driving business success. However, many businesses struggle to harness this potential due to a lack of understanding and effective utilization of data within their culture. This book is a comprehensive guide that unveils the transformative power of data and provides actionable insights to cultivate a data-driven organizational culture.\n\nThe book emphasizes data strategy and data governance's pivotal role in cultivating a mature data culture using practical insights, frameworks, and best practices. This approach ensures robust data culture structures that uphold data integrity, accessibility, and accountability. These structures operate on the people, processes, and technology through analytics, literacy, governance, process management, and data inventory management.\n\nThe authors introduce the groundbreaking Usage and Flow Data Culture Model, a unique framework that enables organizations to evaluate and reshape their data culture based on distinct cultural types: Preservationist, Protectionist, Traditional, and Progressive. Each culture type is carefully dissected, revealing associated challenges and opportunities, uncovering suitable strategies in the process. \n\nDeveloping a worthy data culture necessitates a shift in mindset and the development of relevant skills across the organization. Building a Data Culture is your roadmap to fostering data literacy, promoting data-driven decision-making, and cultivating a data-driven mindset.  \n\nWhat You'll Learn\n\nAssess your organization's current data culture\nIdentify cultural strengths and weaknesses within your organization\nDevelop a data governance program\nDefine data policies and standards and establish decision-making processes\n\nWho This Book is For\n\nProfessionals and leaders across various industries who are interested in building a data culture within their organizations. The typical reader may have a background in data management, analytics, business intelligence, or technology, but the book is designed to be accessible to a wide range of readers with varying levels of expertise.","tags":["Data","Data Governance"]},{"id":"9780123970336","language":"en","level":"Intermediate to advanced","title":"Measuring Data Quality for Ongoing Improvement","authors":["Laura Sebastian-Coleman"],"pages":"star rating fill","publication_date":"December 2012","description":"The Data Quality Assessment Framework shows you how to measure and monitor data quality, ensuring quality over time. You’ll start with general concepts of measurement and work your way through a detailed framework of more than three dozen measurement types related to five objective dimensions of quality: completeness, timeliness, consistency, validity, and integrity. Ongoing measurement, rather than one time activities will help your organization reach a new level of data quality. This plain-language approach to measuring data can be understood by both business and IT and provides practical guidance on how to apply the DQAF within any organization enabling you to prioritize measurements and effectively report on results. Strategies for using data measurement to govern and improve the quality of data and guidelines for applying the framework within a data asset are included. You’ll come away able to prioritize which measurement types to implement, knowing where to place them in a data flow and how frequently to measure. Common conceptual models for defining and storing of data quality results for purposes of trend analysis are also included as well as generic business requirements for ongoing measuring and monitoring including calculations and comparisons that make the measurements meaningful and help understand trends and detect anomalies.\n\nDemonstrates how to leverage a technology independent data quality measurement framework for your specific business priorities and data quality challenges\nEnables discussions between business and IT with a non-technical vocabulary for data quality measurement\nDescribes how to measure data quality on an ongoing basis with generic measurement types that can be applied to any situation","tags":["IT Operations","Service Administration","Database Administration","Data Quality"]},{"id":"9781803246758","language":"en","level":"Intermediate to advanced","title":"Data Literacy in Practice","authors":["Angelika Klidas","Kevin Hanegan"],"pages":"star rating fill","publication_date":"November 2022","description":"\"Data Literacy in Practice\" teaches readers to unlock the power of data for making smarter decisions. You'll learn how to understand and work with data, gain the ability to derive actionable insights, and develop the skills required for data-informed decision-making.\n\nWhat this Book will help me do\n\nUnderstand the basics of data literacy and the importance of data in decision-making.\nLearn to visualize data effectively using charts and graphs tailored to your audience.\nMaster the application of the four-pillar model for organizational data literacy advancement.\nDevelop proficiency in managing data environments and assessing data quality.\nBecome competent in deriving actionable insights and critical questioning for better analysis.\n\nAuthor(s)\n\nAngelika Klidas and Kevin Hanegan are pioneers in the field of data literacy with extensive experience in data analytics. Both are seasoned educators at top universities and bring their expertise to this book to help readers understand and leverage the power of data.\n\nWho is it for?\n\n\"Data Literacy in Practice\" is ideal for data analysts, professionals, and teams looking to enhance their data literacy skills. Readers should have a desire to utilize data effectively in their roles, regardless of prior experience. The book is designed to guide both beginners starting out and those who aim to deepen their knowledge.","tags":["Data","Data Science"]},{"id":"9780128012659","language":"en","level":"Intermediate to advanced","title":"CMDB Systems","authors":["Dennis Drogseth","Rick Sturm","Dan Twing"],"pages":"star rating fill","publication_date":"March 2015","description":"CMDB Systems: Making Change Work in the Age of Cloud and Agile shows you how an integrated database across all areas of an organization’s information system can help make organizations more efficient reduce challenges during change management and reduce total cost of ownership (TCO). In addition, this valuable reference provides guidelines that will enable you to avoid the pitfalls that cause CMDB projects to fail and actually shorten the time required to achieve an implementation of a CMDB. Drawing upon extensive experience and using illustrative real world examples, Rick Sturm, Dennis Drogseth and Dan Twing discuss:\n\nUnique insights from extensive industry exposure, research and consulting on the evolution of CMDB/CMS technology and ongoing dialog with the vendor community in terms of current and future CMDB/CMS design and plans\nProven and structured best practices for CMDB deployments\nClear and documented insights into the impacts of cloud computing and other advances on CMDB/CMS futures\nDiscover unique insights from industry experts who consult on the evolution of CMDB/CMS technology and will show you the steps needed to successfully plan, design and implement CMDB\nCovers related use-cases from retail, manufacturing and financial verticals from real-world CMDB deployments\nProvides structured best practices for CMDB deployments\nDiscusses how CMDB adoption can lower total cost of ownership, increase efficiency and optimize the IT enterprise","tags":["Data","Data Engineering"]},{"id":"9781484298930","language":"en","level":"Intermediate to advanced","title":"Modern Software Testing Techniques: A Practical Guide for Developers and Testers","authors":["István Forgács","Attila Kovács"],"pages":"star rating fill","publication_date":"December 2023","description":"Many books have been written about software testing, but most of them discuss the general framework of testing from a traditional perspective. Unfortunately, traditional test design techniques are often ineffective and unreliable for revealing the various kinds of faults that may occur. This book introduces three new software testing techniques: Two-Phase Model-Based Testing, the Action-State Testing, and the General Predicate Testing, all of which work best when applied with efficient fault revealing capabilities.\n\nYou’ll start with a short recap of software testing, focusing on why risk analysis is obligatory, how to classify bugs practically, and how fault-based testing can be used for improving test design. You’ll then see how action-state testing merges the benefits of state transition testing and use case testing into a unified approach. Moving on you’ll look at general predicate testing and how it serves as an extension of boundary value analysis, encompassing morecomplex predicates. \n\nTwo-phase model-based testing represents an advanced approach where the model does not necessarily need to be machine-readable; human readability suffices. The first phase involves a high-level model from which abstract tests are generated. Upon manual execution of these tests, the test code is generated. Rather than calculating output values, they are merely checked for conformity. The last part of this book contains a chapter on how developers and testers can help each other and work as a collaborative team. \n\nWhat You'll Learn\n\nApply efficient test design techniques for detecting domain faults\nWork with modeling techniques that combine all the advantages of state transition testing and uses case testing\nGrasp the two-phase model-based testing technique\nUse test design efficiently to find almost all the bugs in an application\n\nWho This Book Is For\n\nSoftware developers, QA engineers, and, business analysts","tags":["Data","Data Science","Data Science Tasks","A/B Testing"]},{"id":"9781484261866","language":"en","level":"Beginner to intermediate","title":"BigQuery for Data Warehousing: Managed Data Analysis in the Google Cloud","authors":["Mark Mucchetti"],"pages":"539","publication_date":"September 2020","description":"Create a data warehouse, complete with reporting and dashboards using Google’s BigQuery technology. This book takes you from the basic concepts of data warehousing through the design, build, load, and maintenance phases. You will build capabilities to capture data from the operational environment, and then mine and analyze that data for insight into making your business more successful. You will gain practical knowledge about how to use BigQuery to solve data challenges in your organization.\nBigQuery is a managed cloud platform from Google that provides enterprise data warehousing and reporting capabilities. Part I of this book shows you how to design and provision a data warehouse in the BigQuery platform. Part II teaches you how to load and stream your operational data into the warehouse to make it ready for analysis and reporting. Parts III and IV cover querying and maintaining, helping you keep your information relevant with other Google Cloud Platform services and advanced BigQuery. Part V takes reporting to the next level by showing you how to create dashboards to provide at-a-glance visual representations of your business situation. Part VI provides an introduction to data science with BigQuery, covering machine learning and Jupyter notebooks.\nWhat You Will Learn\nDesign a data warehouse for your project or organization\nLoad data from a variety of external and internal sources\nIntegrate other Google Cloud Platform services for more complex workflows\nMaintain and scale your data warehouse as your organization grows\nAnalyze, report, and create dashboards on the information in the warehouse\nBecome familiar with machine learning techniques using BigQuery ML\nWho This Book Is For\nDevelopers who want to provide business users with fast, reliable, and insightful analysis from operational data, and data analysts interested in a cloud-based solution that avoids the pain of provisioning their own servers.","tags":["Data","Data Engineering","Google BigQuery"]},{"id":"9781484298404","language":"en","level":"Intermediate to advanced","title":"Procedural Programming with PostgreSQL PL/pgSQL: Design Complex Database-Centric Applications with PL/pgSQL","authors":["Baji Shaik","Dinesh Kumar Chemuduru"],"pages":"326","publication_date":"October 2023","description":"Learn the fundamentals of PL/PGSQL, the programming language of PostgreSQL which is most robust Open Source Relational Database. This book provides practical insights into developing database code objects such as functions and procedures, with a focus on effectively handling strings, numbers, and arrays to achieve desired outcomes, and transaction management.\n\nThe unique approach to handling Triggers in PostgreSQL ensures that both functionality and performance are maintained without compromise. You'll gain proficiency in writing inline/anonymous server-side code within the limitations, along with learning essential debugging and profiling techniques. Additionally, the book delves into statistical analysis of PL/PGSQL code and offers valuable knowledge on managing exceptions while writing code blocks. \n\nFinally, you'll explore the installation and configuration of extensions to enhance the performance of stored procedures and functions.\n\nWhat You'll Learn\n\nUnderstand the PL/PGSQL concepts\nLearn to debug, profile, and optimize PL/PGSQL code\nStudy linting PL/PGSQL code\nReview transaction management within PL/PGSQL code\nWork with developer friendly features like operators, casts, and aggregators\n\nWho Is This Book For\n\nApp developers, database migration consultants, and database administrators.","tags":["Data","Data Engineering","Relational Databases","PostgreSQL"]},{"id":"9780128147627","language":"en","level":"Beginner to intermediate","title":"Data Science, 2nd Edition","authors":["Vijay Kotu","Bala Deshpande"],"pages":"568","publication_date":"November 2018","description":"Learn the basics of Data Science through an easy to understand conceptual framework and immediately practice using RapidMiner platform. Whether you are brand new to data science or working on your tenth project, this book will show you how to analyze data, uncover hidden patterns and relationships to aid important decisions and predictions.\n\nData Science has become an essential tool to extract value from data for any organization that collects, stores and processes data as part of its operations. This book is ideal for business users, data analysts, business analysts, engineers, and analytics professionals and for anyone who works with data.\n\nYou’ll be able to:\n\nGain the necessary knowledge of different data science techniques to extract value from data.\n\nMaster the concepts and inner workings of 30 commonly used powerful data science algorithms.\n\nImplement step-by-step data science process using using RapidMiner, an open source GUI based data science platform\n\nData Science techniques covered: Exploratory data analysis, Visualization, Decision trees, Rule induction, k-nearest neighbors, Naïve Bayesian classifiers, Artificial neural networks, Deep learning, Support vector machines, Ensemble models, Random forests, Regression, Recommendation engines, Association analysis, K-Means and Density based clustering, Self organizing maps, Text mining, Time series forecasting, Anomaly detection, Feature selection and more...\n\nContains fully updated content on data science, including tactics on how to mine business data for information\nPresents simple explanations for over twenty powerful data science techniques\nEnables the practical use of data science algorithms without the need for programming\nDemonstrates processes with practical use cases\nIntroduces each algorithm or technique and explains the workings of a data science algorithm in plain language\nDescribes the commonly used setup options for the open source tool RapidMiner","tags":["Data","Data Science"]},{"id":"9783111591070","language":"en","level":"Beginner","title":"An Introduction to Self-Report Measurement","authors":["Michael G. Elasmar"],"pages":"226","publication_date":"April 2025","description":"This book covers the science of measuring the invisible building blocks of thought processes that are useful for understanding humans, including technology users, media consumers, and consumers of goods and services. It provides:\n\nAn explanation of what self-report measurement entails for beginners;\nA clear set of assumptions needed in order for self-report measures to yield valuable information;\nA mindset that needs to be adopted when using self-report measurement in the contexts of surveys and experiments;\nGuidance for extracting opinion from social media text content and integrating AI;\nA roadmap for quantifying the errors associated with self-report measurement.","tags":["Data","Data Science","Data Science Tasks","Statistics"]},{"id":"9781783987344","language":"en","level":"Beginner to intermediate","title":"Mastering Gephi Network Visualization","authors":["Ken Cherven"],"pages":"378","publication_date":"January 2015","description":"Mastering Gephi Network Visualization is your comprehensive guide to creating sophisticated network graphs with Gephi. Within these pages, you'll learn how to analyze and interpret network data effectively, employing advanced techniques to uncover patterns and insights. This book is perfect for turning complex datasets into visually stunning and informative graphs.\n\nWhat this Book will help me do\n\nEffectively use Gephi to create and refine network visualizations.\nChoose appropriate layouts and filters for your network data, improving clarity.\nAnalyze network statistics to uncover meaningful patterns and relationships.\nSegregate a network into components for targeted data analysis.\nExport and present your visualizations effectively for reports and presentations.\n\nAuthor(s)\n\nThe authors of Mastering Gephi Network Visualization are experts in data visualization and network analysis. With years of experience using Gephi in practical applications, they bring a wealth of knowledge to the topic. Their teaching methodology emphasizes clarity and hands-on application, ensuring readers can apply the concepts easily and effectively.\n\nWho is it for?\n\nThis book is ideal for analysts, data scientists, and researchers who work with network data and wish to visualize it effectively. Prior experience with Gephi is helpful but not necessary, as all concepts are introduced step-by-step. Readers with any level of expertise in network visualization will find this book informative. If you're looking to produce engaging network graphs for data analysis, this is the right book for you.","tags":["Data","Data Science","Data Science Tasks","Data Visualization","Gephi"]},{"id":"9781935182856","language":"en","level":"Intermediate to advanced","title":"Tika in Action","authors":["Jukka Zitting","Chris Mattmann"],"pages":"star rating fill","publication_date":"November 2011","description":"Tika in Action is a hands-on guide to content mining with Apache Tika. The book's many examples and case studies offer real-world experience from domains ranging from search engines to digital asset management and scientific data processing.\n\nAbout the Technology\n\nTika is an Apache toolkit that has built into it everything you and your app need to know about file formats. Using Tika, your applications can discover and extract content from digital documents in almost any format, including exotic ones.\n\nAbout the Book\n\nTika in Action is the ultimate guide to content mining using Apache Tika. You'll learn how to pull usable information from otherwise inaccessible sources, including internet media and file archives. This example-rich book teaches you to build and extend applications based on real-world experience with search engines, digital asset management, and scientific data processing. In addition to architectural overviews, you'll find detailed chapters on features like metadata extraction, automatic language detection, and custom parser development.\n\nWhat's Inside\nCrack MS Word, PDF, HTML, and ZIP\nIntegrate with search engines, CMS, and other data sources\nLearn through experimentation\nMany examples\nAbout the Reader\n\nThis book requires no previous knowledge of Tika or text mining techniques. It assumes a working knowledge of Java.\n\nAbout the Authors\n\nChris Mattmann is an information architect experienced in the construction of large data-intensive systems. Jukka Zitting is a core Tika developer, a member of the JCR expert group, and chairman of the Apache Jackrabbit project.\n\nQuotesBy Tika's two main creators and maintainers.- Jérôme Charron, WebPulseEasily the most definitive guide to this great new text analysis toolkit.- John Guthrie, SAPAn easy-to-read guide--plenty of technical content.- Rick Wagner, Red HatThere's not a single page of 'inaction' in the entire book!- Sean Kelly, Technologist, NASAComplete, practical, accurate- Julien Nioche, DigitalPebble Ltd","tags":["Data","Data Engineering","Tika"]},{"id":"9781439882719","language":"en","level":"Intermediate to advanced","title":"Stochastic Financial Models","authors":["Douglas Kennedy"],"pages":"264","publication_date":"April 2016","description":"Developed from the esteemed author's advanced undergraduate and graduate courses at the University of Cambridge, this text provides a hands-on, sound introduction to mathematical finance. Assuming no prior knowledge of stochastic calculus or measure-theoretic probability, the author includes the relevant mathematical background as well as many exercises with solutions. He first presents the classical topics of utility and the mean-variance approach to portfolio choice. Focusing on derivative pricing, the text then covers the binomial model, the general discrete-time model, Brownian motion, the Black-Scholes model, and various interest-rate models.","tags":["Data","Data Science","Data Science Tasks","Statistics"]},{"id":"9781484253281","language":"en","level":"Beginner to intermediate","title":"Jumpstart Snowflake: A Step-by-Step Guide to Modern Cloud Analytics","authors":["Dmitry Anoshin","Dmitry Shirokov","Donna Strok"],"pages":"star rating fill","publication_date":"December 2019","description":"Explore the modern market of data analytics platforms and the benefits of using Snowflake computing, the data warehouse built for the cloud.\n\nWith the rise of cloud technologies, organizations prefer to deploy their analytics using cloud providers such as Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform. Cloud vendors are offering modern data platforms for building cloud analytics solutions to collect data and consolidate into single storage solutions that provide insights for business users. The core of any analytics framework is the data warehouse, and previously customers did not have many choices of platform to use.\n\nSnowflake was built specifically for the cloud and it is a true game changer for the analytics market. This book will help onboard you to Snowflake, present best practices to deploy, and use the Snowflake data warehouse. In addition, it covers modern analytics architecture and use cases. It provides use cases of integration with leading analytics software such as Matillion ETL, Tableau, and Databricks.  Finally, it covers migration scenarios for on-premise legacy data warehouses.\n\nWhat You Will Learn\n\nKnow the key functionalities of Snowflake\nSet up security and access with cluster\nBulk load data into Snowflake using the COPY command\nMigrate from a legacy data warehouse to Snowflake\nintegrate the Snowflake data platform with modern business intelligence (BI) and data integration tools\n\nWho This Book Is For\n\nThose working with data warehouse and business intelligence (BI) technologies, and existing and potential Snowflake users","tags":["Data","Data Engineering","Snowflake"]},{"id":"0642572052836","language":"en","level":"Intermediate","title":"Introduction to Pandas","authors":["George Mount"],"publication_date":"June 2024","description":"This series will equip learners with various techniques for efficient data manipulation, crucial for optimizing analysis workflows. It addresses common data challenges and teaches skills in importing, cleaning and transforming, and presenting data, enhancing analytical precision and speed.","tags":["Data","Data Science","Data Science Tools","Pandas"]},{"id":"9781118650233","language":"en","level":"Beginner","title":"Understanding Uncertainty, Revised Edition","authors":["Dennis V. Lindley"],"pages":"424","publication_date":"December 2013","description":"Praise for the First Edition\n\n\"...a reference for everyone who is interested in knowing and handling uncertainty.\"\n\n—Journal of Applied Statistics\n\nThe critically acclaimed First Edition of Understanding Uncertainty provided a study of uncertainty addressed to scholars in all fields, showing that uncertainty could be measured by probability, and that probability obeyed three basic rules that enabled uncertainty to be handled sensibly in everyday life. These ideas were extended to embrace the scientific method and to show how decisions, containing an uncertain element, could be rationally made.\n\nFeaturing new material, the Revised Edition remains the go-to guide for uncertainty and decision making, providing further applications at an accessible level including:\n\nA critical study of transitivity, a basic concept in probability\n\nA discussion of how the failure of the financial sector to use the proper approach to uncertainty may have contributed to the recent recession\n\nA consideration of betting, showing that a bookmaker's odds are not expressions of probability\n\nApplications of the book's thesis to statistics\n\nA demonstration that some techniques currently popular in statistics, like significance tests, may be unsound, even seriously misleading, because they violate the rules of probability\n\nUnderstanding Uncertainty, Revised Edition is ideal for students studying probability or statistics and for anyone interested in one of the most fascinating and vibrant fields of study in contemporary science and mathematics.","tags":["Data","Data Science","Data Science Tasks","Statistics"]},{"id":"9780415806329","language":"en","level":"Intermediate to advanced","title":"Research Methods for Studying Groups and Teams","authors":["Andrea Hollingshead","Marshall Scott Poole"],"pages":"10","publication_date":"May 2012","description":"This volume provides an overview of the methodological issues and challenges inherent in the study of small groups from the perspective of seasoned researchers in communication, psychology and other fields in the behavioral and social sciences. It summarizes the current state of group methods in a format that is readable, insightful, and useful for both new and experienced group researchers. This collection of essays will inspire new and established researchers alike to look beyond their current methodological approaches, covering both traditional and new methods for studying groups and exploring the full range of groups in face-to-face and online settings.\n\nThe volume will be an important addition to graduate study on group research and will be a valuable reference for established group researchers, consultants and other practitioners. The essays in this volume when considered as a whole will be a contemporary interdisciplinary integration on group research methods.","tags":["Data","Data Science","Data Science Tasks","Statistics","Survey Methodologies"]},{"id":"9781098135836","language":"en","level":"Beginner to intermediate","title":"Unlock Complex and Streaming Data with Declarative Data Pipelines","authors":["Ori Rafael","Roy Hasson","Rick Bilodeau"],"pages":"37","publication_date":"July 2022","description":"Unlocking the value of modern data is critical for data-driven companies. This report provides a concise, practical guide to building a data architecture that efficiently delivers big, complex, and streaming data to both internal users and customers.\n\nAuthors Ori Rafael, Roy Hasson, and Rick Bilodeau from Upsolver examine how modern data pipelines can improve business outcomes. Tech leaders and data engineers will explore the role these pipelines play in the data architecture and learn how to intelligently consider tradeoffs between different data architecture patterns and data pipeline development approaches.\n\nYou will:\n\nExamine how recent changes in data, data management systems, and data consumption patterns have made data pipelines challenging to engineer\nLearn how three data architecture patterns (event sourcing, stateful streaming, and declarative data pipelines) can help you upgrade your practices to address modern data\nCompare five approaches for building modern data pipelines, including pure data replication, ELT over a data warehouse, Apache Spark over data lakes, declarative pipelines over data lakes, and declarative data lake staging to a data warehouse","tags":["Data","Data Engineering","Storage Repositories","Data Lake"]},{"id":"9781466572904","language":"en","level":"Beginner","title":"Exercises and Solutions in Statistical Theory","authors":["Lawrence L. Kupper","Brian. H Neelon","Sean M. O'Brien"],"pages":"388","publication_date":"June 2013","description":"This book helps readers obtain an in-depth understanding of statistical theory by working on and reviewing solutions to interesting and challenging exercises of practical importance. Unlike similar books, this one incorporates many exercises that apply to real-world settings and provides much more thorough solutions. The exercises and selected detailed solutions cover from basic probability theory through to the theory of statistical inference. By mastering the theoretical statistical strategies necessary to solve the exercises, readers will be prepared to successfully study even higher-level statistical theory.","tags":["Data","Data Science","Data Science Tasks","Statistics"]},{"id":"9780071608466","language":"en","level":"Beginner","title":"Databases A Beginner's Guide","authors":["Andy Oppel"],"pages":"408","publication_date":"May 2009","description":"Essential Database Skills--Made Easy!\n\nLearn standard database design and management techniques applicable to any type of database. Featuring clear examples using both Microsoft Access and Oracle, Databases: A Beginner's Guide begins by showing you how to use Structured Query Language (SQL) to create and access database objects. Then, you'll discover how to implement logical design using normalization, transform the logical design into a physical database, and handle data and process modeling. You'll also get details on database security, online analytical processing (OLAP), connecting databases to applications, and integrating XML and object content into databases.\n\nDesigned for Easy Learning\n\nKey Skills & Concepts--Chapter-opening lists of specific skills covered in the chapter\nAsk the Expert--Q&A sections filled with bonus information and helpful tips\nTry This--Hands-on exercises that show you how to apply your skills\nNotes--Extra information related to the topic being covered\nSelf Tests--Chapter-ending quizzes to test your knowledge","tags":["Data","Data Engineering","SQL"]},{"id":"9781783554812","language":"en","level":"Intermediate to advanced","title":"Leaflet.js Essentials","authors":["Paul Crickard III"],"pages":"180","publication_date":"August 2014","description":"Leaflet.js Essentials is a practical guide designed to help web developers create engaging, mobile-friendly map applications using the Leaflet.js library. Through clear step-by-step tutorials, you will gain the skills to integrate interactive mapping features into your web projects.\n\nWhat this Book will help me do\n\nBuild web maps integrating Tile Layers and Web Mapping Services.\nDevelop interactive maps using Leaflet.js and JavaScript.\nAdd GeoJSON data and create custom map markers.\nCreate advanced visualizations such as heatmaps and choropleth maps.\nEnhance maps using third-party plugins and additional tools.\n\nAuthor(s)\n\nPaul Crickard III is an experienced software developer and an expert in geospatial technologies. With a passion for teaching complex topics in an accessible way, Paul has helped many developers integrate geospatial functionalities into their projects. His practical approach to Leaflet in this book equips developers with actionable knowledge.\n\nWho is it for?\n\nThis book is ideal for web developers with a basic knowledge of JavaScript looking to enhance their projects with interactive maps. It suits both beginners to geospatial technologies and those familiar with mapping concepts. If you're aiming to create engaging maps or want to leverage Leaflet for app development, this is the right book for you.","tags":["Data","Data Engineering","Location Data","Geographic Information System (GIS)","Web Mapping"]},{"id":"9781784390815","language":"en","level":"Beginner to intermediate","title":"R for Data Science Cookbook","authors":["Prabhanjan Narayanachar Tattar","Yu-Wei, Chiu (David Chiu)"],"pages":"452","publication_date":"July 2016","description":"The \"R for Data Science Cookbook\" is your comprehensive guide to tackling data problems using R. Focusing on practical applications, you will learn data manipulation, visualization, statistical inference, and machine learning with a hands-on approach using popular R packages.\n\nWhat this Book will help me do\n\nMaster the use of R's functional programming features to streamline your analysis workflows.\nExtract, transform, and visualize data effectively using robust R packages like dplyr and ggplot2.\nLearn to create intuitive and professional visualizations and reports that communicate insights effectively.\nImplement key statistical modeling and machine learning techniques to solve real-world problems.\nAcquire expertise in data mining techniques, including clustering and association rule mining.\n\nAuthor(s)\n\nYu-Wei Chiu, also known as David Chiu, is an experienced data scientist and educator. With a solid technical background in using R for data science, he combines theory with practical applications in his writing. David's approachable style and rich examples make complex topics accessible and engaging for learners.\n\nWho is it for?\n\nThis book is perfect for individuals who already have a foundation in R and are looking to deepen their expertise in applying R to data science tasks. Ideal readers are analysts and statisticians eager to solve real-world problems using practical tools. If you're aspiring to work effectively with large data sets or want to learn versatile data analysis techniques, this book is designed for you. It bridges the gap between theoretical knowledge and actionable skills, making it invaluable for professionals and learners alike.","tags":["Data","Data Science","Data Science Tools","R"]},{"id":"9781398618268","language":"en","level":"Beginner to intermediate","title":"Using R in HR Analytics","authors":["Dr. Martin Edwards","Kirsten Edwards","Daisung Jang"],"pages":"480","publication_date":"October 2024","description":"Understand how to use R and R Studio to analyse HR data and deliver insights that drive workforce and business performance.","tags":["Data","Data Science","Data Science Tools","R"]},{"id":"9780470012864","language":"en","level":"Intermediate to advanced","title":"Strategic Modelling and Business Dynamics: A Feedback Systems Approach","authors":["John Morecroft"],"pages":"464","publication_date":"September 2007","description":"John Morecroft's book is an ideal text for students interested in system modelling and its application to a range of real world problems. The book covers all that is necessary to develop expertise in system dynamics modelling and through the range of applications makes a persuasive case for the power and scope of the approach. As such it will appeal to practitioners as well as students.\n\nRobert Dyson, Professor of Operational Research, Associate Dean, Warwick Business School.\n\nMuch more than an introduction, John Morecroft's Strategic Modelling and Business Dynamics uses interactive \"management flight simulators\" to create an engaging and effective learning environment in which readers, whatever their background, can develop their intuition about complex dynamic systems. The numerous examples provide a rich test-bed for the development of systems thinking and modelling skills\n\nJohn Sterman, Jay W. Forrester Professor of Management, MIT Sloan School of Management\n\nThis book, with its vivid examples and simulators, will help to bring modelling, system dynamics and simulation into the mainstream of management education where they now belong.\n\nJohn A. Quelch, Professor of Marketing, Harvard Business School, Former Dean of London Business School\n\nThis text fills the gap between texts focusing on the purely descriptive systems approach and the more technical system dynamics ones.\n\nAnn van Ackere, Professor of Decision Sciences, HEC Lausanne, Universit? de Lausanne\n\nStrategic modelling based on system dynamics is a powerful tool for understanding how firms adapt to a changing environment. The author demonstrates the appeal and power of business modelling to make sense of strategic initiatives and to anticipate their impacts through simulation. The book offers various simulators that allow readers to conduct their own policy experiments.\n\nDr. Erich Zahn, Professor of Strategic Management, Betriebswirtschaftliches Institut, University of Stuttgart\n\nA website to accompany the book can be found at www.wiley.com/college/morecroft housing supplementary material for both students and lecturers.","tags":["Data","Data Engineering","Data Models"]},{"id":"9781118416747","language":"en","level":"Intermediate to advanced","title":"Heuristics in Analytics: A Practical Perspective of What Influences Our Analytical World","authors":["Carlos Andre Reis Pinheiro","Fiona McNeill"],"pages":"225","publication_date":"March 2014","description":"A practical guide to deploying mathematical and statistical models when performing analytics\n\nThe Heuristics in Analytics describes analytic processes and how they fit into the heuristic world around us. In spite of the strong heuristic characteristics of the analytical processes, this important book emphasizes the need to have the proper tools to engage analytics. It describes the analytical process from the exploratory analysis in respect to business scenarios and corporate environments, to model developments; and from statistics, probability, stochastic, mathematics, and artificial intelligence; to the deployments and possible outcomes.\n\nDescribes the overall analytical process in terms of modeling, deployment, and application\n\nPresents distinct analytical approaches such as statistical, probabilistic, stochastic, and mathematical\n\nOffers a new perspective of the randomness in analytical modeling\n\nIncludes case studies on the entire analytical process using telecom companies based in Brazil, Ireland, Turkey, United Sates, and Canada\n\nRandomness holds a strong impact in the everyday world. It makes sense, then, that analytics are put in place to understand business occurrences, marketplace scenarios, and consumer behavior. The Heuristics in Analytics uniquely shows how random events on a daily basis might completely change expectations, predictions, and behaviors, particularly in corporate environments, and how companies can build a proper analytical strategy to diminish the effect of randomness in business actions.","tags":["Data","Data Science"]},{"id":"9783111001494","language":"en","level":"Intermediate to advanced","title":"Probabilistic Benchmarking","authors":["Andrew Banasiewicz"],"pages":"261","publication_date":"September 2024","description":"What is a ‘good’ outcome? In relation to others, and in relation to the past? Commonly associated with the ideas of benchmarking and baselining, comparative assessment is an important part of organizational management, but this broadly defined undertaking lacks clear conceptual framing and methodological foundations. At the same time, the readily available transactional data make robust tracking and measurement possible at an unprecedented scale, but also accentuate the impact of assessment paradox: To be truly meaningful, exact magnitudes-expressed values often need to be ‘translated’ into qualitative, assessment-laden categories, but that task is impeded by lack of established approaches for doing so.\n\nInspired by these observations, Probabilistic Benchmarking frames the notions of benchmarking and baselining as two complementary but distinct mechanisms of comparative assessment that make use of informational contents of organizational data to contribute unbiased, systematic, and consistent evaluation of outcomes or states of interest. In that general context, this book provides much-needed conceptual and methodological clarity to guide construction and use of benchmarks and baselines, and re-casts the idea of assessment standards in the context of data-derived estimates, to better align the practice of comparative assessment with the emerging realities of the Age of Data.\n\nThis pioneering research-based but application-minded book bridges the gap between theory and practice. It will greatly benefit professionals, business students and others interested in the broad domain of organizational assessment.","tags":["IT Operations","Service Administration","Database Administration","Data Quality"]},{"id":"9780133498820","language":"en","level":"Beginner to intermediate","title":"Modern Analytics Methodologies: Driving Business Value with Analytics","authors":["Michele Chambers","Thomas W. Dinsmore"],"pages":"272","publication_date":"August 2014","description":"Create a complete roadmap for capitalizing on analytics to grow topline revenue and build shareholder value in your unique organization! Modern Analytics Methodologies goes far beyond the classic Analytics Maturity Model to help you overcome the gaps between your current analytics capabilities and where you need to go. Pioneering analytics experts Michele Chambers and Thomas Dinsmore help you implement analytics that supports your strategy, aligns with your culture, and serves your customers and stakeholders.\n\nDrawing on work with dozens of leading enterprises, Michele Chambers and Thomas Dinsmore describe high-value applications from many industries, and help you systematically identify and deliver on your company's best opportunities. Writing for both professionals and students, they show how to: \n\nLeverage the convergence of macro trends ranging from \"flattening\" and \"green\" to Big Data and machine learning\n\nGo beyond the Analytics Maturity Model: power your unique business strategy with an equally focused analytics strategy\n\nLink key business objectives with core characteristics of your organization, value chain, and stakeholders\n\nTake advantage of game changing opportunities before competitors do\n\nEffectively integrate the managerial and operational aspects of analytics\n\nMeasure performance with dashboards, scorecards, visualization, simulation, and more\n\nPrioritize and score prospective analytics projects\n\nIdentify \"Quick Wins\" you can implement while you're planning for the long-term\n\nBuild an effective Analytic Program Office to make your roadmap persistent\n\nUpdate and revise your roadmap for new needs and technologies\n\nModern Analytics Methodologies will be an indispensable resource for any executive or professional concerned with analytics, including Chief Analytics Officers; Chief Data Officers; Chief Scientists; Chief Marketing Officers; Chief Risk Officers; Chief Strategy Officers; VPs of Analytics or Big Data; data scientists; business strategists; and line-of-business executives.","tags":["Data","Data Science"]},{"id":"9781783988327","language":"en","level":"Beginner to intermediate","title":"Mastering Python Data Visualization","authors":["Kirthi Raman"],"pages":"star rating fill","publication_date":"October 2015","description":"Mastering Python Data Visualization provides thorough, hands-on guidance for creating impactful visual representations of data by leveraging Python's powerful libraries such as Matplotlib, Pandas, and Scikit-Learn. By following this book, you will gain proficiency in understanding data, performing analyses, and ultimately presenting your findings in a clear and engaging way.\n\nWhat this Book will help me do\n\nEffectively transform raw data into insightful visualizations using Python's rich ecosystem of libraries.\nUnderstand and apply best practices for selecting the most appropriate visualization techniques for different datasets and objectives.\nMaster the use of Python for interactive plotting, regression analysis, clustering, and classification tasks.\nDevelop a solid foundation in data visualization aesthetics and how to convey information clearly through visuals.\nUtilize Python for specialized fields such as finance, bioinformatics, and social network analysis, incorporating advanced computation techniques.\n\nAuthor(s)\n\nKirthi Raman is an experienced data scientist and Python advocate with a strong background in technical computing and data visualization. He has hands-on experience in using Python's ecosystem to solve real-world data problems and a passion for sharing knowledge. Raman's writing focuses on blending practical insights with comprehensive explanations, ensuring readers not only learn the tools but also apply them effectively.\n\nWho is it for?\n\nThis book is ideal for data analysts, data scientists, and researchers who want to deepen their knowledge of Python-based data visualization techniques. It requires readers to have a basic understanding of Python and data manipulation. If your goal is to create professional and informative visual narratives that are both visually appealing and data-driven, this book is for you.","tags":["Data","Data Science","Data Science Tasks","Data Visualization","Python Viz Tools"]},{"id":"0596002653","language":"en","level":"Intermediate to advanced","title":"MySQL Reference Manual","authors":["Michael Widenius","David Axmark","Kaj Arno"],"pages":"816","publication_date":"June 2002","description":"MySQL is the most popular SQL database in the open source community and is used almost universally by web sites running on open source systems. As powerful and flexible as it is lightweight and efficient, MySQL packs a large feature set into a very small and fast engine that now runs on more than 500,000 servers. This renowned online manual that has supported MySQL administrators and database developers for years is now available in paperback format. This book is an exact reproduction of the MySQL Reference Manual from the MySQL development team's Web site, minus some non-technical appendices. This version covers MySQL 4.0.\n\nMany sophisticated topics appear in this comprehensive manual, ranging from the hitches you may run into when first installing MySQL to internals that will help you tune your queries. MySQL Reference Manual contains all the comprehensive reference material one would expect for building the product, running administrative utilities, and using various API as well as MySQL's rich version of SQL. In addition, you can turn a page and find such unexpected riches as:\n\nA thorough comparison of MySQL with SQL standards and other databases\n\nA discussion of privileges and suggested uses of privileges to enhance security\n\nDirections for replicating a database and for running several MySQL servers on a single system\n\nDirections for initializing a database from a flat file\n\nGuidelines for estimating the performance of different queries\n\nA far-reaching discussion of optimization, with reference to the implementation of MySQL\n\nInvestigations of the differences between data types and the pros and cons of each type of number, string, or timestamp\n\nAn extended inquiry into the effects of using delayed inserts\n\nA candid explanation of why various errors occur and how to recover from them\n\nTips for weighted, full-text searches\n\nDetailed descriptions of the features, strengths, and weaknesses of available table formats\n\nA guide to adding new functions to MySQL\n\nNo serious MySQL user should be without this book.","tags":["Data","Data Engineering","Relational Databases","MySQL"]},{"id":"9781484233726","language":"en","level":"Intermediate to advanced","title":"Oracle SQL Revealed: Executing Business Logic in the Database Engine","authors":["Alex Reprintsev"],"pages":"star rating fill","publication_date":"April 2018","description":"Write queries using little-known, but powerful, SQL features implemented in Oracle's database engine. You will be able to take advantage of Oracle’s power in implementing business logic, thereby maximizing return from your company’s investment in Oracle Database products.\nImportant features and aspects of SQL covered in this book include the model clause, row pattern matching, analytic and aggregate functions, and recursive subquery factoring, just to name a few. The focus is on implementing business logic in pure SQL, with a comparison of different approaches that can be used to write SELECT statements to return results that drive good decision making and competitive action in the marketplace.  \nThis book covers features that are often not well known, and sometimes not implemented in competing products. Chapters on query transformation and logical execution order provide a grasp of the big picture in which the individual SQL features described in the other chapters are executed. Also included are a discussion on when to use the procedural capabilities from PL/SQL, and a series of examples showing different mixes of SQL features being applied in common types of queries that you are likely to encounter. \nWhat You Will Learn\nGain competitive advantage from Oracle SQL\nKnow when to step up to PL/SQL versus staying in SQL\nBecome familiar with query transformations and join mechanics\nApply the model clause and analytic functions to business intelligence queries\nMake use of features that are specific to Oracle Database, such as row pattern matching\nUnderstand the pros and cons of different SQL approaches to solving common query tasks\nTraverse hierarchies using CONNECT BY and recursive subquery factoring\nWho This Book Is For\nDatabase programmers withsome Oracle Database experience. The book is also for SQL developers who are moving to the Oracle Database platform or want to learn unique features of its query engine. Both audiences will learn to apply the full power of Oracle’s own SQL dialect to commonly encountered types of business questions and query challenges.","tags":["Data","Data Engineering","SQL"]},{"id":"9781484287804","language":"en","level":"Beginner to intermediate","title":"R 4 Data Science Quick Reference: A Pocket Guide to APIs, Libraries, and Packages","authors":["Thomas Mailund"],"pages":"231","publication_date":"October 2022","description":"In this handy, quick reference book you'll be introduced to several R data science packages, with examples of how to use each of them. All concepts will be covered concisely, with many illustrative examples using the following APIs: readr, dibble, forecasts, lubridate, stringr, tidyr, magnittr, dplyr, purrr, ggplot2, modelr, and more.\nWith R 4 Data Science Quick Reference, you'll have the code, APIs, and insights to write data science-based applications in the R programming language. You'll also be able to carry out data analysis. All source code used in the book is freely available on GitHub..  \nWhat You'll Learn\nImplement applicable R 4 programming language specification features\nImport data with readr\nWork with categories using forcats, time and dates with lubridate, and strings with stringr\nFormat data using tidyr and then transform that data using magrittr and dplyr\nWrite functions with R for data science, data mining, and analytics-based applications\nVisualize data with ggplot2 and fit data to models using modelr\nWho This Book Is For\nProgrammers new to R's data science, data mining, and analytics packages.  Some prior coding experience with R in general is recommended.","tags":["Data","Data Science","Data Science Tools","R"]},{"id":"9781398611764","language":"en","level":"Intermediate to advanced","title":"The Business Models Handbook, 2nd Edition","authors":["Paul Hague"],"pages":"392","publication_date":"August 2023","description":"Enhance your business planning with this collection of the most valuable business models, including expertly explained theory, case studies and supporting templates.","tags":["Data","Data Engineering","Data Models"]},{"id":"9781782174110","language":"en","level":"Beginner to intermediate","title":"Real Time Analytics with SAP Hana","authors":["Vinay Singh"],"pages":"star rating fill","publication_date":"October 2015","description":"\"Real Time Analytics with SAP HANA\" offers a comprehensive, step-by-step guide to mastering analytics and data modeling in the powerful SAP HANA environment. This book covers everything from basic data modeling concepts to more advanced techniques like creating calculation views and leveraging SAP HANA artifacts.\n\nWhat this Book will help me do\n\nUnderstand and build analytics/data models in the SAP HANA environment.\nCreate schemas, packages, and delivery units in SAP HANA Studio.\nMaster real-time data replication using SLT and SAP HANA Studio.\nLearn about full-text search, fuzzy search, and other analytical capabilities in SAP HANA.\nDevelop comprehensive use cases combining SAP HANA concepts and tools.\n\nAuthor(s)\n\nVinay Singh, the author of this book, is a seasoned SAP HANA expert with extensive experience in analytics and data modeling. He has worked on multiple SAP HANA implementation and migration projects and brings this expertise into his writing. His practical examples and hands-on approach make SAP HANA concepts accessible to learners at all levels.\n\nWho is it for?\n\nThis book is ideal for SAP HANA data modelers, developers, implementation or migration consultants, project managers, and architects. It is designed for individuals aiming to enhance their skill set in SAP HANA and master real-time analytics. Whether you are actively working with SAP HANA or just starting, this book will serve as a valuable guide.","tags":["Data","Data Engineering","Relational Databases"]},{"id":"0201703661","language":"en","level":"Intermediate to advanced","title":"SAP® BW: A Step-by-Step Guide","authors":["Ph.D. Biao Fu","P.E. Henry Fu"],"pages":"star rating fill","publication_date":"July 2002","description":"SAP BW has recently come to the fore as a valuable tool for developing data warehouses that accurately and effectively support critical business decision making. It facilitates easy-to-use and high-performance extraction, transfer, transformation, and loading of data from a variety of data sources, including such comprehensive business management systems as SAP R/3.\n\nThis practitioner's guide uses step-by-step instructions complete with a plethora of screen captures to illustrate key SAP BW functionalities. It demonstrates how SAP BW implements the fundamental star schema and solves the major challenges inherent in the creation of data warehouses: performance, reliability, and error-handling. Using a real-world business scenario as a running example, SAP® BW presents a comprehensive view of the technology, from underlying concepts and basic techniques through its most sophisticated capabilities.\n\nSpecific topics covered include:\n\nCreating an InfoCube and loading the data\n\nChecking the accuracy of data with BW Monitor and the Persistent Staging Area (PSA)\n\nCreating queries to generate reports using Business Explorer (BEx)\n\nManaging user authorization with the Profile Generator\n\nAdvanced InfoCube design techniques\n\nAggregates and multicubes\n\nWorking with the Operational Data Store (ODS)\n\nInstalling business content and creating an R/3 source system in BW\n\nLoading data from SAP R/3 into SAP BW\n\nData maintenance\n\nPerformance tuning, including parallel query option and data packet sizing\n\nObject transport\n\nAlthough the focus is on the core SAP BW technology, this book also discusses other relevant technologies, including Basis, ABAP (Advanced Business Application Programming), ALE (Application Link Enabling), and ASAP (Accelerated SAP) for BW.\n\nWith the clear explanations and practical techniques presented in SAP® BW information systems professionals will gain both the general understanding and specific skills necessary to create high quality data warehouses that support effective decision making.\n\n0201703661B07092002","tags":["Data","Data Engineering","SAP"]},{"id":"9783111326252","language":"en","level":"Intermediate to advanced","title":"Non-Stationary Stochastic Processes Estimation","authors":["Maksym Luz","Mikhail Moklyachuk"],"pages":"310","publication_date":"May 2024","description":"The problem of forecasting future values of economic and physical processes, the problem of restoring lost information, cleaning signals or other data observations from noise, is magnified in an information-laden word. Methods of stochastic processes estimation depend on two main factors.\n\nThe first factor is construction of a model of the process being investigated.\n\nThe second factor is the available information about the structure of the process under consideration. In this book, we propose results of the investigation of the problem of mean square optimal estimation (extrapolation, interpolation, and filtering) of linear functionals\n\ndepending on unobserved values of stochastic sequences and processes\n\nwith periodically stationary and long memory multiplicative seasonal increments.\n\nFormulas for calculating the mean square errors and the spectral characteristics of the optimal estimates of the functionals are derived in the case of spectral certainty, where\n\nspectral structure of the considered sequences and processes are exactly known.\n\nIn the case where spectral densities of the sequences and processes are not known exactly while some sets of admissible spectral densities are given, we apply the minimax-robust method of estimation.","tags":["Data","Data Science","Data Science Tasks","Statistics","Time Series","Forecasting"]},{"id":"9781484211366","language":"en","level":"Intermediate to advanced","title":"Expert SQL Server In-Memory OLTP","authors":["Dmitri Korotkevitch"],"pages":"272","publication_date":"September 2015","description":"Expert SQL Server In-Memory OLTP is a deep dive into one of the most significant features of SQL Server 2014 – support for In-Memory Online Transaction Processing. The book describes the architecture and internals of the In-Memory OLTP Engine and explains how to develop, deploy, and maintain systems using it. With it you can dramatically increase transactional throughput to handle thousands of transactions per second supporting millions of customers.\n\nDmitri Korotkevitch is the five-star author of Pro SQL Server Internals, and now brings his same combination of clear thinking and deep expertise to the question of how to recognize the opportunities and benefit from Microsoft’s In-Memory OLTP feature set in SQL Server 2014.\n\nLearn the architecture and the internals in order to recognize when in-memory OLTP can make a difference. Learn useful scenarios for thoughtfully incorporating In-Memory support into existing applications. Recognize opportunities for In-Memory OLTP in new development. Don’t be without Dmitri Korotkevitch and the deep expertise he imparts in Expert SQL Server In-Memory OLTP as you move forward in using SQL Server’s new and important In-Memory OLTP feature set.\n\nCovers In-Memory OLTP internals and architecture, including data storage, indexing, multi-version concurrency control, transaction logging, and recovery\nIllustrates In-Memory OLTP programmability and the process of native compilation\nGuides in using In-Memory OLTP in new development and existing systems.","tags":["Data","Data Engineering","SQL"]},{"id":"9780738440835","language":"en","level":"Intermediate to advanced","title":"IBM Cognos Dynamic Cubes","authors":["Dmitriy Beryoza","MaryAlice Campbell","Cesar Cardorelle"],"pages":"star rating fill","publication_date":"July 2015","description":"IBM® Cognos® Business Intelligence (BI) provides a proven enterprise BI platform with an open data strategy. Cognos BI provides customers with the ability to use data from any source, package it into a business model, and make it available to consumers in various interfaces that are tailored to the task.\n\nIBM Cognos Dynamic Cubes complements the existing Cognos BI capabilities and continues the tradition of an open data model. It focuses on extending the scalability of the IBM Cognos platform to enable speed-of-thought analytics over terabytes of enterprise data, without having to invest in a new data warehouse appliance. This capability adds a new level of query intelligence so you can unleash the power of your enterprise data warehouse.\n\nThis IBM Redbooks® publication addresses IBM Cognos Business Intelligence V10.2.2 and specifically, the IBM Cognos Dynamic Cubes capabilities. This book can help you in the following ways:\n\nUnderstand core features of the Cognos Dynamic Cubes capabilities of Cognos BI V10.2\n\nLearn by example with practical scenarios by using the IBM Cognos samples\n\nThis book uses fictional business scenarios to demonstrate the power and capabilities of IBM Cognos Dynamic Cubes. It primarily focuses on the roles of the modeler, administrator, and IT architect.","tags":["Data","Data Science","Analytics Platforms","Cognos"]},{"id":"9781783984923","language":"en","level":"Intermediate to advanced","title":"ElasticSearch Blueprints","authors":["Vineeth Mohan"],"pages":"star rating fill","publication_date":"July 2015","description":"Dive into search technology with \"ElasticSearch Blueprints\"! This is the perfect project-based guide to help you master Elasticsearch. You will learn how to build and design scalable, effective search solutions, improve search relevancy, manage data efficiently, perform analytics, and visualize your data in comprehensive ways.\n\nWhat this Book will help me do\n\nBuild and fine-tune scalable search engine features with Elasticsearch.\nDesign and implement accurate ecommerce search solutions using filters.\nAnalyze and visualize data with Elasticsearch's powerful data aggregation capabilities.\nIncrease search relevancy and enhance user query assistance using analyzers.\nIncorporate enhanced data organization methods, including parent-child relationships.\n\nAuthor(s)\n\nNone Mohan is an experienced professional specializing in search technologies. With a strong technical background, they have engaged deeply with Elasticsearch, creating solutions that address practical challenges. Their approach focuses on making technical topics accessible, guiding readers step-by-step through projects.\n\nWho is it for?\n\nThis book is tailored for data professionals, application developers, and enthusiasts eager to delve into search technologies. Whether you're beginning with Elasticsearch or aiming to refine your skills, this guide will advance your expertise. By working through practical cases, you'll gain confidence in using Elasticsearch effectively to meet diverse requirements.","tags":["Data","Data Engineering","Search","Elasticsearch"]},{"id":"9781484202920","language":"en","level":"Intermediate to advanced","title":"MATLAB Optimization Techniques","authors":["César Pérez López"],"pages":"star rating fill","publication_date":"November 2014","description":"MATLAB is a high-level language and environment for numerical computation, visualization, and programming. Using MATLAB, you can analyze data, develop algorithms, and create models and applications. The language, tools, and built-in math functions enable you to explore multiple approaches and reach a solution faster than with spreadsheets or traditional programming languages, such as C/C++ or Java.\n\nMATLAB Optimization Techniques introduces you to the MATLAB language with practical hands-on instructions and results, allowing you to quickly achieve your goals. It begins by introducing the MATLAB environment and the structure of MATLAB programming before moving on to the mathematics of optimization. The central part of the book is dedicated to MATLABs Optimization Toolbox, which implements state-of-the-art algorithms for solving multiobjective problems, non-linear minimization with boundary conditions and restrictions, minimax optimization, semi-infinitely constrained minimization and linear and quadratic programming. A wide range of exercises and examples are included, illustrating the most widely used optimization methods.","tags":["Data","Data Science","Data Science Tools","MATLAB"]},{"id":"9781398602953","language":"en","level":"Beginner to intermediate","title":"Delivering Data Analytics","authors":["Nicholas Kelly"],"pages":"232","publication_date":"December 2021","description":"Increase adoption and usage of data analytics with a step-by-step agile process to gain stakeholder buy-in and create actionable business value.","tags":["Data","Data Science","Business Intelligence","Prescriptive Analytics"]},{"id":"53863MIT59109","language":"en","level":"Intermediate to advanced","title":"Unleashing the Potential of Supply Chain Analytics","authors":["Melissa R. Bowers","Adam Petrie","Mary C. Holcomb"],"pages":"3","publication_date":"October 2017","description":"To gain competitive advantage from supply chain analytics, companies need to reduce the time it takes to act on the insights those analytics generate.","tags":["Data","Data Engineering","Streaming & Messaging","Real-Time Analytics"]},{"id":"9781040269329","language":"en","level":"Intermediate to advanced","title":"Continuous-Time Signals and Systems, 2nd Edition","authors":["Oktay Alkin"],"pages":"766","publication_date":"March 2025","description":"Drawing on author’s 30+ years of teaching experience, ”Continuous-Time Signals and Systems: A MATLAB Integrated Approach” represents a novel and comprehensive approach to understanding signals and systems theory.","tags":["Data","Data Science","Data Science Tools","MATLAB"]},{"id":"0738438421","language":"en","level":"Intermediate to advanced","title":"IBM and Cisco: Together for a World Class Data Center","authors":["Pall Beck","Peter Clemens","Santiago Freitas"],"pages":"star rating fill","publication_date":"July 2013","description":"This IBM® Redbooks® publication is an IBM and Cisco collaboration that articulates how IBM and Cisco can bring the benefits of their respective companies to the modern data center.\n\nIt documents the architectures, solutions, and benefits that can be achieved by implementing a data center based on IBM server, storage, and integrated systems, with the broader Cisco network.\n\nWe describe how to design a state-of-the art data center and networking infrastructure combining Cisco and IBM solutions. The objective is to provide a reference guide for customers looking to build an infrastructure that is optimized for virtualization, is highly available, is interoperable, and is efficient in terms of power and space consumption. It will explain the technologies used to build the infrastructure, provide use cases, and give guidance on deployments.","tags":["Data","Data Engineering","IBM"]},{"id":"073843681X","language":"en","level":"Intermediate to advanced","title":"Scaling BPM Adoption: From Project to Program with IBM Business Process Manager","authors":["Lisa Dyer","Flournoy Henry","Ines Lehmann"],"pages":"266","publication_date":"March 2012","description":"Your first Business Process Management (BPM) project is a crucial first step on your BPM journey. It is important to begin this journey with a philosophy of change that allows you to avoid common pitfalls that lead to failed BPM projects, and ultimately, poor BPM adoption. This IBM® Redbooks® publication describes the methodology and best practices that lead to a successful project and how to use that success to scale to enterprise-wide BPM adoption. This updated edition contains a new chapter on planning a BPM project.\n\nThe intended audience for this book includes all people who participate in the discovery, planning, delivery, deployment, and continuous improvement activities for a business process. These roles include process owners, process participants, subject matter experts (SMEs) from the operational business, and technologists responsible for delivery, including BPM analysts, BPM solution architects, BPM administrators, and BPM developers.","tags":["Data","Data Engineering","IBM"]},{"id":"9781786460189","language":"en","level":"Intermediate to advanced","title":"Mastering Elasticsearch 5.x - Third Edition","authors":["Bharvi Dixit"],"pages":"star rating fill","publication_date":"February 2017","description":"This comprehensive guide dives deep into the functionalities of Elasticsearch 5, the widely-used search and analytics engine. Leveraging the power of Apache Lucene, this book will help you understand advanced concepts like querying, indexing, and cluster management to build efficient and scalable search solutions.\n\nWhat this Book will help me do\n\nMaster advanced features of Elasticsearch such as text scoring, sharding, and aggregation.\nUnderstand how to handle big data efficiently using Elasticsearch's architecture.\nLearn practical implementation techniques for Elasticsearch features through hands-on examples.\nDevelop custom plugins for Elasticsearch to tailor its functionalities to specific needs.\nScale and optimize Elasticsearch clusters for high performance in production environments.\n\nAuthor(s)\n\nBharvi Dixit is an experienced software engineer and a recognized expert in implementing Elasticsearch solutions. With a strong background in distributed systems and database management, Bharvi's writing is informed by real-world experience and a focus on practical applications.\n\nWho is it for?\n\nThis book is ideal for developers and data engineers with existing experience in Elasticsearch who wish to deepen their knowledge. It serves as a valuable resource for professionals tasked with creating scalable search applications. A working understanding of Elasticsearch basics and query DSL is recommended to fully benefit from this guide.","tags":["Data","Data Engineering","Search","Elasticsearch"]},{"id":"9781558607538","language":"en","level":"Intermediate to advanced","title":"Database Tuning","authors":["Dennis Shasha","Philippe Bonnet"],"pages":"440","publication_date":"June 2002","description":"Tuning your database for optimal performance means more than following a few short steps in a vendor-specific guide. For maximum improvement, you need a broad and deep knowledge of basic tuning principles, the ability to gather data in a systematic way, and the skill to make your system run faster. This is an art as well as a science, and Database Tuning: Principles, Experiments, and Troubleshooting Techniques will help you develop portable skills that will allow you to tune a wide variety of database systems on a multitude of hardware and operating systems. Further, these skills, combined with the scripts provided for validating results, are exactly what you need to evaluate competing database products and to choose the right one.\n\nForward by Jim Gray, with invited chapters by Joe Celko and Alberto Lerner\nIncludes industrial contributions by Bill McKenna (RedBrick/Informix), Hany Saleeb (Oracle), Tim Shetler (TimesTen), Judy Smith (Deutsche Bank), and Ron Yorita (IBM)\nCovers the entire system environment: hardware, operating system, transactions, indexes, queries, table design, and application analysis\nContains experiments (scripts available on the author's site) to help you verify a system's effectiveness in your own environment\nPresents special topics, including data warehousing, Web support, main memory databases, specialized databases, and financial time series\nDescribes performance-monitoring techniques that will help you recognize and troubleshoot problems","tags":["Data","Data Engineering","Relational Databases"]},{"id":"9781466507531","language":"en","level":"Intermediate to advanced","title":"Age-Period-Cohort Analysis","authors":["Yang Yang","Kenneth C. Land"],"pages":"352","publication_date":"April 2016","description":"This book explores the ways in which statistical models, methods, and research designs can be used to open new possibilities for APC analysis. Within a single, consistent HAPC-GLMM statistical modeling framework, the authors synthesize APC models and methods for three research designs: age-by-time period tables of population rates or proportions, repeated cross-section sample surveys, and accelerated longitudinal panel studies. They show how the empirical application of the models to various problems leads to many fascinating findings on how outcome variables develop along the age, period, and cohort dimensions.","tags":["Data","Data Science","Data Science Tasks","Statistics"]},{"id":"9781484224243","language":"en","level":"Beginner","title":"Apache HBase Primer","authors":["Deepak Vohra"],"pages":"star rating fill","publication_date":"November 2016","description":"Learn the fundamental foundations and concepts of the Apache HBase (NoSQL) open source database. It covers the HBase data model, architecture, schema design, API, and administration.\n\nApache HBase is the database for the Apache Hadoop framework. HBase is a column family based NoSQL database that provides a flexible schema model.\n\nWhat You'll Learn\n\nWork with the core concepts of HBase\n\nDiscover the HBase data model, schema design, and architecture\n\nUse the HBase API and administration\n\nWho This Book Is For\n\nApache HBase (NoSQL) database users, designers, developers, and admins.","tags":["Data","Data Engineering","NoSQL Databases","HBase"]},{"id":"059600852X","language":"en","level":"Intermediate to advanced","title":"Fixing Access Annoyances","authors":["Evan Callahan","Phil Mitchell"],"pages":"star rating fill","publication_date":"February 2006","description":"When an application is part of the Microsoft Office suite, it's sure to be a leader in its field. In the realm of desktop database management, Access is top dog with millions of users. But this is one dog that can bite. Although Access is a powerful, relational tool with the fetching talents of a Labrador, it's not an easy beast to train.\n\nStill, millions of users count on Access for everything from managing parts databases to running Web catalogs to working as a front end to mondo SQL databases. But Access is chockablock with annoyances---report hassles, query conundrums, VBA bugs, arcane error messages, and more.\n\nO'Reilly's Annoyances series offer real-world help, right now, and Fixing Access Annoyances continues tradition. You'll not only squash bugs and workaround Access' limits, but you'll learn how to use Access to the max, whether you're a newbie or a seasoned pro. Coverage includes install/configuration annoyances, building better tables and queries, creating forms that work right, generating reliable and sophisticated reports, pulling in data from a variety of sources, crafting macros and VBA code to customize Access, and much more.\n\nYou could grab those other books for help, but do they solve problems from page one? Meet a book of a different stripe. The authors come armed with knowledge of the program's quirks, design hurdles and interface snags. They provide you with battle plans in Fixing Access Annoyances to save you time and bouts of hair pulling.\n\nStop information from spiraling out of control when working with Access and trying to make this #$@@#$ thing work! Don't let its quirks, bugs, and troublemaking features beat you. Who you gonna call for help? Instead of waiting on the line for tech support or searching for the answer on the Internet with its too many resources to find exactly what you need, take control of databases with Fixing Access Annoyances, your partner on database adventures.","tags":["Data","Data Engineering","Database Management Tools","Microsoft Access"]},{"id":"9781498786669","language":"en","level":"Beginner to intermediate","title":"Displaying Time Series, Spatial, and Space-Time Data with R","authors":["Oscar Perpinan Lamigueiro"],"pages":"208","publication_date":"April 2014","description":"Code and Methods for Creating High-Quality Data GraphicsA data graphic is not only a static image, but it also tells a story about the data. It activates cognitive processes that are able to detect patterns and discover information not readily available with the raw data. This is particularly true for time series, spatial, and space-time datasets.F","tags":["Data","Data Science","Data Science Tasks","Statistics","Time Series"]},{"id":"9798888650097","language":"en","level":"Intermediate to advanced","title":"Building Table Views with Phoenix LiveView","authors":["Peter Ullrich"],"pages":"star rating fill","publication_date":"January 2023","description":"Data is at the core of every business, but it is useless if nobody can access and analyze it. Learn how to generate business value by making your data accessible with advanced table UIs. This definitive guide teaches you how to bring your data to the fingertips of nontechnical users with advanced features like pagination, sorting, filtering, and infinity scrolling. Build reactive and reuseable table components by leveraging Phoenix LiveView, schemaless changesets, and Ecto query composition. Table UIs are the bread and butter for every web developer, so it is time to learn how to build them right.\n\nAs a web developer, you have to build tables. Lots and lots of tables. With table UIs making up such a significant part of your daily work, you need to know how to build the right table for the task, with all the needed features. Building a simple table is easy, but tables only become really useful with advanced features like pagination, sorting, and filtering. That;s where building a table can quickly become complicated. This book shows you how to implement advanced table features in a clean and reusable way.\n\nYou'll build fast and interactive table UIs by leveraging Phoenix LiveView. Make vast amounts of data manageable with common but complex features like pagination, sorting, filtering, and inifinity scrolling. Use SOLID coding principles to make your queries reusable with query composition. Compartmentalize your UI with LiveComponents and learn how to handle user input securely with schemaless changesets. Share your view onto the data painlessly by storing your search parameters in the URL.\n\nData is one of the most valuable assets of your business, but you cannot unlock its potential if you don't know how to make it accessible. This book shows you how to deliver that data to your users' fingertips quickly.\n\nWhat You Need:\n\nYou'll need Elixir 1.12 or later, Erlang/OTP 24 or later, Phoenix 1.6 or later, and PostgreSQL installed on your machine.","tags":["Data","Data Science","Data Science Tasks","Data Visualization","Tableau"]},{"id":"9781449357160","language":"en","level":"Beginner to intermediate","title":"Learning R","authors":["Richard Cotton"],"pages":"star rating fill","publication_date":"September 2013","description":"Learn how to perform data analysis with the R language and software environment, even if you have little or no programming experience. With the tutorials in this hands-on guide, youâ??ll learn how to use the essential R tools you need to know to analyze data, including data types and programming concepts.\n\nThe second half of Learning R shows you real data analysis in action by covering everything from importing data to publishing your results. Each chapter in the book includes a quiz on what youâ??ve learned, and concludes with exercises, most of which involve writing R code.\n\nWrite a simple R program, and discover what the language can do\nUse data types such as vectors, arrays, lists, data frames, and strings\nExecute code conditionally or repeatedly with branches and loops\nApply R add-on packages, and package your own work for others\nLearn how to clean data you import from a variety of sources\nUnderstand data through visualization and summary statistics\nUse statistical models to pass quantitative judgments about data and make predictions\nLearn what to do when things go wrong while writing data analysis code","tags":["Data","Data Science","Data Science Tools","R"]},{"id":"9780470414644","language":"en","level":"Intermediate to advanced","title":"Developing Web Applications with Perl, memcached, MySQL® and Apache","authors":["Patrick Galbraith"],"pages":"star rating fill","publication_date":"July 2009","description":"The only book to address using cache to enhance and speed up Web application development\n\nDevelopers use Apache, MySQL, memcached, and Perl to build dynamic Web sites that store information within the MySQL database; this is the only book to address using these technologies together to alleviate the database load in Web development\n\nCovers each of the four systems and shows how to install, set up, and administer them; then shows the reader how to put the parts together to start building applications\n\nExplains the benefits of a base perl library for code re-use, and provides sample applications that demonstrate in a practical way the information covered in the previous chapters\n\nExamines monitoring, performance, and security, with a problem-solving chapter that walks the reader through solving real-world issues","tags":["Data","Data Engineering","Relational Databases","MySQL"]},{"id":"9781118356302","language":"en","level":"Intermediate to advanced","title":"Structural Equation Modeling: Applications Using Mplus","authors":["Jichuan Wang","Xiaoqian Wang"],"pages":"star rating fill","publication_date":"October 2012","description":"A reference guide for applications of SEM using Mplus\n\nStructural Equation Modeling: Applications Using Mplus is intended as both a teaching resource and a reference guide. Written in non-mathematical terms, this book focuses on the conceptual and practical aspects of Structural Equation Modeling (SEM). Basic concepts and examples of various SEM models are demonstrated along with recently developed advanced methods, such as mixture modeling and model-based power analysis and sample size estimate for SEM. The statistical modeling program, Mplus, is also featured and provides researchers with a flexible tool to analyze their data with an easy-to-use interface and graphical displays of data and analysis results.\n\nKey features:\n\nPresents a useful reference guide for applications of SEM whilst systematically demonstrating various advanced SEM models, such as multi-group and mixture models using Mplus.\n\nDiscusses and demonstrates various SEM models using both cross-sectional and longitudinal data with both continuous and categorical outcomes.\n\nProvides step-by-step instructions of model specification and estimation, as well as detail interpretation of Mplus results.\n\nExplores different methods for sample size estimate and statistical power analysis for SEM.\n\nBy following the examples provided in this book, readers will be able to build their own SEM models using Mplus. Teachers, graduate students, and researchers in social sciences and health studies will also benefit from this book.","tags":["Data","Data Engineering","Data Models"]},{"id":"9781119438861","language":"en","level":"Beginner to intermediate","title":"The Sentient Enterprise","authors":["Oliver Ratzesberger","Mohanbir Sawhney","Thomas H. Davenport"],"pages":"176","publication_date":"October 2017","description":"Mohan and Oliver have been very fortunate to have intimate views into the data challenges that face the largest organizations and institutions across every possible industry—and what they have been hearing about for some time is how the business needs to use data and analytics to their advantage. They continually hear the same issues, such as:\n\nWe're spending valuable meeting time wondering why everyone's data doesn't match up.\nWe can't leverage our economies of scale while remaining agile with data.\nWe need self-serve apps that let the enterprise experiment with data and accelerate the development process.\nWe need to get on a more predictive curve to ensure long-term success.\n\nTo really address the data concerns of today's enterprise, they wanted to find a way to help enterprises achieve the success they seek. Not as a prescriptive process—but a methodology to become agile and leverage data and analytics to drive a competitive advantage.\n\nYou know, it's amazing what can happen when two people with very different perspectives get together to solve a big problem. This evolutionary guide resulted from the a-ha moment between these two influencers at the top of their fields—one, an academic researcher and consultant, and the other, a longtime analytics practitioner and chief product officer at Teradata. Together, they created a powerful framework every type of business can use to connect analytic power, business practices, and human dynamics in ways that can transform what is currently possible.","tags":["Data","Data Engineering"]},{"id":"0642572052553","language":"en","level":"Intermediate","title":"Understanding the Initialization Environment","authors":["George Mount"],"publication_date":"June 2024","description":"This video series explores integrating Python with Excel, teaching data analysts how to automate tasks, enhance data analysis, and create powerful visualizations. It solves efficiency issues in Excel, equipping viewers with skills to streamline workflows and extend Excel's capabilities using Python. You can access the author's GitHub repo here.","tags":["Data","Data Science","Data Science Tasks","Data Visualization","Python Viz Tools"]},{"id":"0738437867","language":"en","level":"Intermediate to advanced","title":"Migration Use Cases with the Migration Manager Version 7.5","authors":["Rebecca Alsop","Mohamed Amine Bourenane","Brian Davis"],"pages":"470","publication_date":"March 2013","description":"By using the Migration Manager, you can migrate configuration content from one production environment to another. The typical use is to migrate configuration content from a development environment to a test environment and then on to production for the Tivoli® process automation engine and its applications, such as IBM® SmartCloud® Control Desk. The goal of migration is to ensure that your production environment fully meets the needs of your users.\n\nThis IBM Redbooks® publication is an update of the existing book Migration Use Cases with the Migration Manager, SG24-7906 and covers the most common migration use cases with the Migration Manager, including the capabilities that were introduced with Tivoli's process automation engine V7.5. These use cases are only a small subset of the possible migration scenarios that can be performed by the Migration Manager, but they were chosen to be representative of the capabilities of the Migration Manager.\n\nIn addition to these use cases, the book presents a migration strategy and a comprehensive chapter about troubleshooting possible migration problems when the Migration Manager is used.\n\nWe strongly suggest that you read Chapter 1, \"Migration strategy\" on page 1 first before reading the other chapters. This chapter give syou a good foundation for all of the migration scenarios that are covered in the book.\n\nThis book is a reference for IT Specialists and IT Architects working on migrating configuration content from one production environment to another by using the Migration Manager.","tags":["Data","Data Engineering","IBM","IBM Tivoli"]},{"id":"9781466592193","language":"en","level":"Beginner to intermediate","title":"Theoretical Foundations of Digital Imaging Using MATLAB","authors":["Leonid P. Yaroslavsky"],"pages":"514","publication_date":"November 2012","description":"Helping readers master digital imaging, this text presents a unified theoretical basis for understanding and designing methods of imaging and image processing. Designed for newcomers to imaging science and engineering, the book covers the subject in its entirety, from image formation to image perfecting. The author avoids using heavy mathematics and derives all formulas in full detail. To facilitate a deeper understanding of the major results, the book includes a number of exercises supported by MATLAB programs, with the code available at www.crcpress.com.","tags":["Data","Data Science","Data Science Tools","MATLAB"]},{"id":"0738488755","language":"en","level":"Intermediate to advanced","title":"Implementing and Testing SOA on IBM System z: A Real Customer Case","authors":["Christian Matthys","Mathias Bonnard","Sylvie Lemariey"],"pages":"166","publication_date":"August 2007","description":"Service-oriented architecture (SOA) is one of the most important topics on the agenda of any IT person. SOA involves a new vision of how to design, develop, and manage applications. It also has new requirements when building an architecture for the underlying infrastructure.\n\nThis IBM Redbooks publication is the result of a project managed in the IBM European Design Center, based in Montpellier, France. The scope of the project involved helping a major worldwide customer in the automotive industry to validate and justify an SOA implementation. In particular, the customer wanted to add new business values to work with its partners, by adding new data models. It also wanted to modernize an infrastructure, by adding new Internet interfaces. The customer faced the need to eradicate an obsolete programming language. Furthermore, it wanted to build a smooth migration path, with as few risks and costs as possible.\n\nThe thought, planning, and architecture of the new system, which included integration of the SOA concepts, was built by the customer with the participation of Atos Origin, a leading international IT services provider. The existing customer IT infrastructure was already built around UNIX systems, IBM System z, non-IBM clusters, SAP solutions, 3270 screens, IMS-DL/I databases, and specific code. SOA was the right solution to connect this existing environment to new components using Java, Web services, and DB2 in particular.\n\nThis book explores the business needs and the architectural choices that were faced by the customer. It describes the mock-ups and prototypes, provides performance numbers that were used to validate the decisions, and explains how they were implemented. It also suggests a generic and riskless solution to eradicate the obsolete programming language.","tags":["Data","Data Engineering","IBM"]},{"id":"0738436690","language":"en","level":"Intermediate to advanced","title":"Threadsafe Considerations for CICS","authors":["Chris Rayns","George Bogner","Philip Hale"],"pages":"416","publication_date":"April 2012","description":"Beginning with IBM® CICS® Version 2, applications can run on TCBs apart from the QR TCB, which has positive implications for improving system throughput and for implementing new technologies inside of CICS. Examples of implementing new technologies include using the IBM MVS™ Java virtual machine (JVM) inside CICS and enabling listener tasks written for other platforms to be imported to run under CICS.\n\nThe newest release, CICS Transaction Server for z/OS® (CICS TS) V4.2, includes scalability enhancements so that you can perform more work more quickly in a single CICS system. The advantage of this enhancement is that you can increase vertical scaling and decrease the need to scale horizontally, reducing the number of regions that are required to run the production business applications. The scalability enhancements in CICS TS V4.2 fall into two broad areas, which are increased usage of open transaction environment (OTE) and of 64-bit storage.\n\nThis IBM Redbooks® publication is a comprehensive guide to threadsafe concepts and implementation for IBM CICS. This book explains how systems programmers, applications developers, and architects can implement threadsafe applications in an environment. It describes the real-world experiences of users, and our own experiences, of migrating applications to be threadsafe. This book also highlights the two most critical aspects of threadsafe applications: system performance and integrity.","tags":["Data","Data Engineering","IBM"]},{"id":"53863MIT59126","language":"en","level":"Beginner to intermediate","title":"The Subtle Sources of Sampling Bias Hiding in Your Data","authors":["Sam Ransbotham"],"pages":"3","publication_date":"October 2017","description":"Plummeting data acquisition costs have been a big part of the surge in business analytics. We have much richer samples of data to use for insight. But more data doesn’t inherently remove sampling bias; in fact, it may make it worse.","tags":["Data","Data Science","Data Science Tasks","Exploratory Data Analysis"]},{"id":"9781484216941","language":"en","level":"Beginner to intermediate","title":"Beginning Elastic Stack","authors":["Vishal Sharma"],"pages":"star rating fill","publication_date":"December 2016","description":"Learn how to install, configure and implement the Elastic Stack (Elasticsearch, Logstash and Kibana) – the invaluable tool for anyone deploying a centralized log management solution for servers and apps.\n\nYou will see how to use and configure Elastic Stack independently and alongside Puppet. Each chapter includes real-world examples and practical troubleshooting tips, enabling you to get up and running with Elastic Stack in record time. Fully customizable and easy to use, Elastic Stack enables you to be on top of your servers all the time, and resolve problems for your clients as fast as possible. Supported by Puppet and available with various plugins.\n\nGet started with Beginning Elastic Stack today and see why many consider Elastic Stack the best option for server log management.\n\nWhat You Will Learn:\n\nInstall and configure Logstash\n\nUse Logstash with Elasticsearch and Kibana\n\nUse Logstash with Puppet and Foreman\n\nCentralize data processing\n\nWho This Book Is For:\n\nAnyone working on multiple servers who needs to search their logs using a web interface. It is ideal for server administrators who have just started their job and need to look after multiple servers efficiently.","tags":["Data","Data Engineering","Search","Elasticsearch","Elastic Stack (ELK Stack)"]},{"id":"0642572051907","language":"en","level":"Intermediate","title":"Row Transformations: Sorting and Filtering","authors":["George Mount"],"publication_date":"June 2024","description":"This series focuses on efficient data cleaning techniques crucial for analysts in various sectors. It teaches methods to automate and streamline data preparation, addressing challenges like merging sources and enhancing data quality, empowering viewers with new data management skills.","tags":["Data","Data Science","Data Science Tasks","Data Wrangling, Preparation, Cleaning"]},{"id":"9780470247969","language":"en","level":"Intermediate to advanced","title":"Professional Microsoft® SQL Server® 2008 Administration","authors":["Brian Knight","Ketan Patel","Wayne Snyder"],"pages":"910","publication_date":"November 2008","description":"SQL Server 2008 represents a sizable jump forward in scalability, performance, and usability for the DBA, developer, and business intelligence (BI) developer. It is no longer unheard of to have 20-terabyte databases running on a SQL Server. SQL Server administration used to just be the job of a database administrator (DBA), but as SQL Server proliferates throughout smaller companies, many developers have begun to act as administrators as well. Additionally, some of the new features in SQL Server are more developer-centric, and poor configuration of these features can result in poor performance. SQL Server now enables you to manage the policies on hundreds of SQL Servers in your environment as if you were managing a single instance. We've provided a comprehensive, tutorial-based book to get you over the learning curve of how to configure and administer SQL Server 2008.\n\nWhether you're an administrator or developer using SQL Server, you can't avoid wearing a DBA hat at some point. Developers often have SQL Server on their own workstations and must provide guidance to the administrator about how they'd like the production configured. Oftentimes, they're responsible for creating the database tables and indexes. Administrators or DBAs support the production servers and often inherit the database from the developer.\n\nThis book is intended for developers, DBAs, and casual users who hope to administer or may already be administering a SQL Server 2008 system and its business intelligence features, such as Integration Services. This book is a professional book, meaning the authors assume that you know the basics about how to query a SQL Server and have some rudimentary concepts of SQL Server already. For example, this book does not show you how to create a database or walk you through the installation of SQL Server using the wizard. Instead, the author of the installation chapter may provide insight into how to use some of the more advanced concepts of the installation. Although this book does not cover how to query a SQL Server database, it does cover how to tune the queries you've already written.\n\nThe first ten chapters of the book are about administering the various areas of SQL Server, including the developer and business intelligence features. Chapter 1 briefly covers the architecture of SQL Server and the changing role of the DBA. Chapters 2 and 3 dive into best practices on installing and upgrading to SQL Server 2008. Managing your SQL Server database instance is talked about in Chapter 4. This chapter also describes some of the hidden tools you may not even know you have.\n\nOnce you know how to manage your SQL Server, you can learn in Chapter 5 how to automate many of the redundant monitoring and maintenance tasks. This chapter also discusses best practices on configuring SQL Server Agent. Chapters 6 and 7 cover how to properly administer and automate many tasks inside of the Microsoft business intelligence products, such as Integration Services and Analysis Services. Developers will find that Chapter 8 is very useful, as it covers how to administer the development features, such as SQL CLR. Chapter 9 explains how to secure your SQL Server from many common threats and how to create logins and users. Chapter 10 covers how to create a SQL Server project and do proper change management in promoting your scripts through the various environments. It also covers the Policy-Based Management framework in SQL Server.\n\nChapters 11 through 15 make up the performance tuning part of the book. Chapter 11 discusses how to choose the right hardware configuration for your SQL Server in order to achieve optimal performance. After the hardware and operating system is configured, Chapter 12 shows you how to optimize your SQL Server instance for the best performance. Chapter 13 describes how to monitor your SQL Server instance for problematic issues such as blocking and locking. Chapters 14 and 15 discuss how to optimize the T-SQL that accesses your tables and then how to index your tables appropriately.\n\nChapters 16 through 20 consist of the high-availability chapters of the book. Chapter 16 covers how to use the various forms of replication, while database mirroring is covered in Chapter 17. Classic issues and best practices with backing up and recovering your database are discussed in Chapter 18. Chapter 19 dives deeply into the role of log shipping in your high-availability strategy, and Chapter 20 presents a step-by-step guide to clustering your SQL Server and Windows 2008 server.\n\nThis edition of the book covers all the same great information we covered in the last book, and we've added loads of new content for SQL Server 2008, which adds numerous new features to improve the DBA's life. In short, the new version of SQL Server focuses on improving your efficiency, the scale of your server, and the performance of your environment, so you can do more in much less time, and with fewer resources and people. This means you can manage many servers at one time using Policy-Based Management, scale your I/O load using compression, and collect valuable information about your environment using data collectors, to name just a few key new features.\n\nTo follow the examples in this book, you will need to have SQL Server 2008 installed. If you wish to learn how to administer the business intelligence features, you need to have Analysis Services and the Integration Services components installed. You need a machine that can support the minimum hardware requirements to run SQL Server 2008; and you also need the AdventureWorks2008 and AdventureWorksDW2008 databases installed. Instructions for accessing these databases can be found in the ReadMe file on this book's Web site.\n\nSome features in this book (especially in the high-availability part) require the Enterprise or Developer Edition of SQL Server. If you do not have this edition, you will still be able to follow through some of the examples in the chapter with Standard Edition.","tags":["Data","Data Engineering","Relational Databases","Microsoft SQL Server"]},{"id":"9780072263053","language":"en","level":"Intermediate to advanced","title":"Oracle Database 10g Performance Tuning Tips & Techniques","authors":["Richard Niemiec"],"pages":"star rating fill","publication_date":"July 2007","description":"\"Offers hundreds of hints, tips, and tricks of the trade that can be useful to any DBA wanting to achieve maximum performance of Oracle applications. No Oracle library would be complete without this book.\" --Ken (Dr. DBA) Jacobs, Vice President of Product Strategy for Server Technologies, Oracle Corporation\n\n\"Rich is the first and last stop for Oracle Database technology and performance tuning. His knowledge is a vital tool that you need to successfully negotiate the waters of Oracle database development.\" --Mike Frey, Principal Architect, Navteq","tags":["Data","Data Engineering","SQL","PL/SQL","1Z0-051 Oracle Database 11g: SQL Fundamentals I"]},{"id":"9783110676143","language":"en","level":"Intermediate to advanced","title":"Predictive Intelligence in Biomedical and Health Informatics","authors":["Rajshree Srivastava","Nhu Gia Nguyen","Ashish Khanna"],"pages":"180","publication_date":"October 2020","description":"Predictive Intelligence in Biomedical and Health Informatics focuses on imaging, computer-aided diagnosis and therapy as well as intelligent biomedical image processing and analysis. It develops computational models, methods and tools for biomedical engineering related to computer-aided diagnostics (CAD), computer-aided surgery (CAS), computational anatomy and bioinformatics. Large volumes of complex data are often a key feature of biomedical and engineering problems and computational intelligence helps to address such problems. Practical and validated solutions to hard biomedical and engineering problems can be developed by the applications of neural networks, support vector machines, reservoir computing, evolutionary optimization, biosignal processing, pattern recognition methods and other techniques to address complex problems of the real world.","tags":["Data","Data Science","Data Science Domains","Bioinformatics"]},{"id":"9781492032786","language":"en","level":"Beginner to intermediate","title":"Learning Apache Drill","authors":["Charles Givre","Paul Rogers"],"pages":"332","publication_date":"November 2018","description":"Get up to speed with Apache Drill, an extensible distributed SQL query engine that reads massive datasets in many popular file formats such as Parquet, JSON, and CSV. Drill reads data in HDFS or in cloud-native storage such as S3 and works with Hive metastores along with distributed databases such as HBase, MongoDB, and relational databases. Drill works everywhere: on your laptop or in your largest cluster.\n\nIn this practical book, Drill committers Charles Givre and Paul Rogers show analysts and data scientists how to query and analyze raw data using this powerful tool. Data scientists today spend about 80% of their time just gathering and cleaning data. With this book, you’ll learn how Drill helps you analyze data more effectively to drive down time to insight.\n\nUse Drill to clean, prepare, and summarize delimited data for further analysis\nQuery file types including logfiles, Parquet, JSON, and other complex formats\nQuery Hadoop, relational databases, MongoDB, and Kafka with standard SQL\nConnect to Drill programmatically using a variety of languages\nUse Drill even with challenging or ambiguous file formats\nPerform sophisticated analysis by extending Drill’s functionality with user-defined functions\nFacilitate data analysis for network security, image metadata, and machine learning","tags":["Data","Data Science","Analytics Platforms","Apache Drill"]},{"id":"9781606491850","language":"en","level":"Intermediate to advanced","title":"Business Intelligence","authors":["Jerzy Surma"],"pages":"star rating fill","publication_date":"March 2011","description":"This book is about using business intelligence as a management information system for supporting managerial decision making. It concentrates primarily on practical business issues and demonstrates how to apply data warehousing and data analytics to support business decision making. This book progresses through a logical sequence, starting with data model infrastructure, then data preparation, followed by data analysis, integration, knowledge discovery, and finally the actual use of discovered knowledge. All examples are based on the most recent achievements in business intelligence. Finally this book outlines an overview of a methodology that takes into account the complexity of developing applications in an integrated business intelligence environment. This book is written for managers, business consultants, and undergraduate and postgraduates students in business administration.","tags":["Data","Data Science","Business Intelligence"]},{"id":"9780749479602","language":"en","level":"Intermediate to advanced","title":"Myths of PR","authors":["Rich Leigh"],"pages":"224","publication_date":"April 2017","description":"Explore some of the most widely-accepted myths that permeate PR with this fascinating examination of the industry.","tags":["Data","Data Science","Data Science as a Profession"]},{"id":"9781484292259","language":"en","level":"Intermediate to advanced","title":"Azure SQL Hyperscale Revealed: High-performance Scalable Solutions for Critical Data Workloads","authors":["Zoran Barać","Daniel Scott-Raynsford"],"pages":"475","publication_date":"March 2023","description":"Take a deep dive into the Azure SQL Database Hyperscale Service Tier and discover a new form of cloud architecture from Microsoft that supports massive databases. The new horizontally scalable architecture, formerly code-named Socrates, allows you to decouple compute nodes from storage layers. This radically different approach dramatically increases the scalability of the service. This book shows you how to leverage Hyperscale to provide next-level scalability, high throughput, and fast performance from large databases in your environment.\nThe book begins by showing how Hyperscale helps you eliminate many of the problems of traditional high-availability and disaster recovery architecture. You’ll learn how Hyperscale overcomes storage capacity limitations and issues with scale-up times and costs. With Hyperscale, your costs do not increase linearly with database size and you can manage more data than ever at a lower cost.\nThe book teaches you how todeploy, configure, and monitor an Azure SQL Hyperscale database in a production environment. The book also covers migrating your current workloads from traditional architecture to Azure SQL Hyperscale. \nWhat You Will Learn\nUnderstand the advantages of Hyperscale over traditional architecture\nDeploy a Hyperscale database on the Azure cloud (interactively and with code)\nConfigure the advanced features of the Hyperscale database tier\nMonitor and scale database performance to suit your needs\nBack up and restore your Azure SQL Hyperscale databases\nImplement disaster recovery and failover capability\nCompare performance of Hyperscale vs traditional architecture\nMigrate existing databases to the Hyperscale service tier\nWho This Book Is For\nSQL architects, data engineers, and DBAs who want the most efficient and cost-effective cloud technologies to run their critical data workloads, and those seeking rapid scalability and high performance and throughput while utilizing large databases","tags":["Data","Data Engineering","Relational Databases","Azure SQL Database"]},{"id":"01120100024SI","language":"en","level":"Intermediate to advanced","title":"NSA and the Cuban Missile Crisis","authors":["Thomas Johnson","David Hatch"],"pages":"14","publication_date":"May 1998","description":"A study of the contributions made by NSA during the Cuban Missile Crisis of 1962.","tags":["Data","Data Engineering","Data Security & Privacy"]},{"id":"9781484224274","language":"en","level":"Intermediate to advanced","title":"Oracle Application Express by Design: Managing Cost, Schedule, and Quality","authors":["Patrick Cimolini"],"pages":"star rating fill","publication_date":"November 2017","description":"Learn the many design decisions that must be made before starting to build a large Oracle Application Express (APEX) application for the cloud or enterprise. \nOne of APEX's key strengths is the fact that it is a Rapid Application Development (RAD) tool. This is also a major weakness when it tempts developers to start coding too soon. Small applications that consist of tens of pages can be coded without a lot of design work because they can be re-factored quickly when design flaws are discovered. Design flaws in large cloud and enterprise applications that consist of hundreds or thousands of pages are not so easy to re-factor due to the time needed to redevelop and retest the application, not to mention the risk of breaking functionality in subtle ways.\nDesigning a large application before coding starts is a profitable exercise because a thoughtful design goes a long way in mitigating cost overruns and schedule slippage while simultaneously enhancing quality. This book takes into account perspectives from other non-developer stakeholders such as maintenance developers, business analysts, testers, technical writers, end users, and business owners. Overlooking these perspectives is one of the chief causes of expensive rework late in the development cycle. \nOracle Application Express by Design illustrates APEX design principles by using architecture diagrams, screen shots, and explicit code snippets to guide developers through the many design choices and complex interrelationship issues that must be evaluated before embarking on large APEX projects. This book:\nGuides you through important, up-front APEX design decisions\nHelps you to optimize your design by keeping all stakeholders in mind\nExplicit code examples show how design impacts cost, schedule, and quality\nWhat You Will Learn\nPick and choose from the list of designs before coding begins\nBake optimal quality into the underlying fabric of an APEX application\nThink and design from outside the developer’s narrow perspective\nOptimize APEX application designs to satisfy multiple stakeholder groups\nEvaluate design options through hands-on, explicit code examples\nDefine and measure success for large cloud and enterprise APEX applications\nWho This Book Is For\nAPEX developers and development teams","tags":["Data","Data Engineering","Oracle Database Solutions"]},{"id":"0738436100","language":"en","level":"Intermediate to advanced","title":"Security on IBM z/VSE","authors":["Helmut Hellner","Ingo Franzki","Antoinette Kaschner"],"pages":"460","publication_date":"November 2011","description":"One of a firm's most valuable resources is its data: client lists, accounting data, employee information, and so on. This critical data has to be securely managed and controlled, and simultaneously made available to those users authorized to see it. The IBM® z/VSE™ system has extensive capabilities to simultaneously share the firm's data among multiple users and protect them. Threats to this data come from a variety of sources. Insider threats, as well as malicious hackers, are not only difficult to detect and prevent—they could have been using resources without the business even being aware that they are there.\n\nThis IBM Redbooks® publication was written to assist z/VSE support and security personnel in providing the enterprise with a safe, secure and manageable environment.\n\nThis book provides an overview of the security provided by z/VSE and the processes for the implementation and configuration of z/VSE security components, Basic Security Manager (BSM), IBM CICS® security, TCP/IP security, single sign-on using LDAP, and connector security.","tags":["Data","Data Engineering","IBM"]},{"id":"0738438073","language":"en","level":"Intermediate to advanced","title":"IBM System Blue Gene Solution: Blue Gene/Q Hardware Installation and Maintenance Guide","authors":["Matt Mattingly","James Milano"],"pages":"198","publication_date":"May 2013","description":"This document is one of a series of IBM® Redbooks® written specifically for the IBM Blue Gene/Q® system. The Blue Gene/Q system is the third generation of massively parallel supercomputers from IBM in the Blue Gene® series. This document explains how to install the Blue Gene/Q rack and the Blue Gene/Q I/O enclosure. It shows you how to remove and replace parts.","tags":["Data","Data Engineering","IBM"]},{"id":"9780738441993","language":"en","level":"Intermediate to advanced","title":"IBM Spectrum Archive Enterprise Edition V1.2.1: Installation and Configuration Guide","authors":["Larry Coyne","Khanh Ngo","Stefan Neff"],"pages":"370","publication_date":"August 2016","description":"This IBM® Redbooks® publication helps you with the planning, installation, and configuration of the new IBM Spectrum™ Archive (formerly IBM Linear Tape File System™ (LTFS)) Enterprise Edition (EE) V1.2.1.0 for the IBM TS3310, IBM TS3500, and IBM TS4500 tape libraries. IBM Spectrum Archive™ EE enables the use of the LTFS for the policy management of tape as a storage tier in a IBM Spectrum Scale™ (formerly IBM General Parallel File System (IBM GPFS™)) based environment and helps encourage the use of tape as a critical tier in the storage environment. This is the second edition of IBM Spectrum Archive V1.2 (SG24-8333-00) although it is based on the prior editions of IBM Linear Tape File System Enterprise Edition V1.1.1.2: Installation and Configuration Guide, SG24-8143.\n\nIBM Spectrum Archive EE can run any application that is designed for disk files on a physical tape media. IBM Spectrum Archive EE supports the IBM Linear Tape-Open (LTO) Ultrium 7, 6, and 5 tape drives in IBM TS3310, TS3500, and TS4500 tape libraries. Also, IBM TS1140 and IBM TS1150 tape drives are supported in TS3500 and TS4500 tape library configurations.\n\nIBM Spectrum Archive EE can play a major role in reducing the cost of storage for data that does not need the access performance of primary disk. The use of IBM Spectrum Archive EE to replace disks with physical tape in Tier 2 and Tier 3 storage can improve data access over other storage solutions because it improves efficiency and streamlines management for files on tape. IBM Spectrum Archive EE simplifies the use of tape by making it transparent to the user and manageable by the administrator under a single infrastructure.\n\nThis publication is intended for anyone who wants to understand more about IBM Spectrum Archive EE planning and implementation. This book is suitable for IBM clients, IBM Business Partners, IBM specialist sales representatives, and technical specialists.","tags":["Data","Data Engineering","IBM"]},{"id":"0738489328","language":"en","level":"Intermediate to advanced","title":"Working with IBM Records Manager","authors":["Wei-Dong Zhu","Serena S Chan","Gunther Flaig"],"pages":"328","publication_date":"August 2007","description":"In a corporate environment, documents are usually created or captured in a decentralized environment with no overall surveillance. Many corporations have no formal process of retaining these documents as records, which can increase storage costs. In addition, when litigation requests occur, companies can spend a huge amount of money and resources to locate records. In the case when a company is not able to locate records or to locate them on a timely manner, the company is subjected to a financial penalty or, more importantly, damage to the company's reputation.\n\nIBM Records Manager is an application and an engine that provides records management capabilities to existing business applications. It provides a single and consistent records management platform to help companies meet government and industry requirements for formal records management.\n\nThis IBM Redbooks publication provides an introduction to records management and IBM Records Manager. Solution architects, designers, and implementers who plan to implement IBM Records Manager will find this book useful. It also serves as a guide for system administrators or records administrators in performing common records management administration tasks in IBM Records Manager. Lastly, the first part of this book serves as a good starting point for anyone who is interested in exploring the world of records management.","tags":["Data","Data Engineering","IBM"]},{"id":"9780738456638","language":"en","level":"Intermediate to advanced","title":"IBM Spectrum Scale: Big Data and Analytics Solution Brief","authors":["Wei G. Gong","Sandeep R. Patil"],"pages":"14","publication_date":"July 2019","description":"This IBM® Redguide™ publication describes big data and analytics deployments that are built on IBM Spectrum Scale™. IBM Spectrum Scale is a proven enterprise-level distributed file system that is a high-performance and cost-effective alternative to Hadoop Distributed File System (HDFS) for Hadoop analytics services.\n\nIBM Spectrum Scale includes NFS, SMB, and Object services and meets the performance that is required by many industry workloads, such as technical computing, big data, analytics, and content management. IBM Spectrum Scale provides world-class, web-based storage management with extreme scalability, flash accelerated performance, and automatic policy-based storage tiering from flash through disk to the cloud, which reduces storage costs up to 90% while improving security and management efficiency in cloud, big data, and analytics environments.\n\nThis Redguide publication is intended for technical professionals (analytics consultants, technical support staff, IT Architects, and IT Specialists) who are responsible for providing Hadoop analytics services and are interested in learning about the benefits of the use of IBM Spectrum Scale as an alternative to HDFS.","tags":["Data","Data Engineering","IBM"]},{"id":"9780738455808","language":"en","level":"Intermediate to advanced","title":"IBM Spectrum Scale Deployment on IBM SoftLayer","authors":["Nikhil Khandelwal","John Lewars","Gautam Shah"],"pages":"28","publication_date":"December 2016","description":"This IBM® Redpaper™ publication describes various activities that are necessary to deploy IBM Spectrum Scale™ on IBM SoftLayer®.","tags":["Data","Data Engineering","IBM"]},{"id":"9781788838689","language":"en","level":"Beginner","title":"Getting Started with Tableau 2018.x","authors":["Tristan Guillevin"],"pages":"396","publication_date":"September 2018","description":"Dive into the world of data visualization with \"Getting Started with Tableau 2018.x.\" This comprehensive guide introduces you to both the fundamental and advanced functionalities of Tableau 2018.x, making it easier to create impactful data visualizations. Learn to unlock Tableau's full potential through practical examples and clear explanations.\n\nWhat this Book will help me do\n\nUnderstand the new Tableau 2018.x features like density, extensions, and transparency and how to leverage them.\nLearn how to connect to data sources, perform transformations, and build efficient data models to support your analysis.\nMaster visualization techniques to design effective and insightful dashboards tailored to business needs.\nExplore advanced concepts such as calculations, cross-database joins, and data blending to handle complex scenarios.\nDevelop the confidence to publish and interact with content on Tableau Server and share your insights effectively.\n\nAuthor(s)\n\nNone Guillevin and None Pires are data visualization experts with extensive experience using Tableau. They aim to make data analysis accessible through hands-on examples and easy-to-follow explanations. Their writing balances clear instruction with practical application, making advanced concepts understandable for all readers.\n\nWho is it for?\n\nThis book is ideal for beginners or experienced BI professionals who wish to gain expertise in Tableau 2018.x. It caters to aspiring analysts and business professionals looking to answer complex business-specific questions through data visualization. Regardless of prior experience in Tableau or other BI tools, this book provides value through a structured learning approach.","tags":["Data","Data Science","Data Science Tasks","Data Visualization","Tableau"]},{"id":"0738438324","language":"en","level":"Intermediate to advanced","title":"IBM System Storage Tape Library Guide for Open Systems","authors":["Larry Coyne","Sandor Alavari","Simon Browne"],"pages":"494","publication_date":"June 2013","description":"This IBM® Redbooks® publication presents a general introduction to Linear Tape-Open (LTO) technology and the implementation of corresponding IBM products. The IBM Enterprise 3592 Tape Drive also is described.\n\nThis tenth edition includes information about the latest enhancements to the IBM Ultrium family of tape drives and tape libraries. In particular, it includes details of the latest IBM LTO Ultrium 6 tape drive technology and its implementation in IBM tape libraries.\n\nInformation is included about the recently released, enhanced, higher-performance ProtecTIER servers and the features of the new version 3.2 server software. The new software also enables a new feature, the File System Interface (FSI).\n\nIt also contains technical information about each IBM tape product for Open Systems. It includes generalized sections about Small Computer System Interface (SCSI) and Fibre Channel connections and multipath architecture configurations.\n\nThis book also includes information about tools and techniques for library management. This edition includes details about Tape System Library Manager (TSLM). TSLM provides consolidation and simplification in large TS3500 Tape Library environments, including the IBM Shuttle Complex.\n\nThis publication is intended for anyone who wants to understand more about IBM tape products and their implementation. This book is suitable for IBM clients, IBM Business Partners, IBM specialist sales representatives, and technical specialists. If you do not have a background in computer tape storage products, you might need to reference other sources of information. In the interest of being concise, topics that are generally understood are not covered in detail.","tags":["Data","Data Engineering","IBM"]},{"id":"9780749453305","language":"en","level":"Beginner to intermediate","title":"Running Your Own Boarding Kennels, 4th Edition","authors":["David Cavill"],"pages":"192","publication_date":"July 2008","description":"Running your own Boarding Kennels is the only guide of its kind which looks at every aspect of running a boarding kennels or cattery, from selecting premises to feeding boaders.","tags":["Data","Data Engineering","Zookeeper"]},{"id":"9781098166618","language":"en","level":null,"title":"Use Tableau Comments to Provide Context to Data Fields and Calculations","authors":["Christopher Gardner"],"pages":"5","publication_date":"January 2024","description":"Tableau is one of today’s most powerful business intelligence analytics and data visualization tools. It empowers people across the organization to see and understand data for better business decision-making. These Shortcuts will provide you with simple tips and tricks for creating charts, dashboards, and stories that turn data into actionable insights.","tags":["Data","Data Science","Data Science Tasks","Data Visualization","Tableau"]},{"id":"0738440450","language":"en","level":"Intermediate to advanced","title":"Reduce Storage Occupancy and Increase Operations Efficiency with IBM zEnterprise Data Compression","authors":["Franco Pinto","Gianmauro De Marchi","Maria Kroos Boisen"],"pages":"162","publication_date":"February 2015","description":"IBM® zEnterprise® Data Compression (zEDC) capability and the Peripheral Component Interconnect Express (PCIe or PCI Express) hardware adapter called zEDC Express were announced in July 2013 as enhancements to the IBM z/OS® V2.1 operating system (OS) and the IBM zEnterprise EC12 (zEC12) and the IBM zEnterprise BC12 (zBC12).\n\nzEDC is optimized for use with large sequential files, and uses an industry-standard compression library. zEDC can help to improve disk usage and optimize cross-platform exchange of data with minimal effect on processor usage.\n\nThe first candidate for such compression was the System Management Facility (SMF), and support for basic sequential access method (BSAM) and queued sequential access method (QSAM) followed in first quarter 2014. IBM software development kit (SDK) 7 for z/OS Java, IBM Encryption Facility for z/OS, IBM Sterling Connect:Direct® for z/OS and an IBM z/VM® guest can also use zEDC Express.\n\nzEDC can also be used for Data Facility Storage Management Subsystem data set services (DFSMSdss) dumps and restores, and for DFSMS hierarchical storage manager (DFSMShsm) when using DFSMSdss for data moves.\n\nThis IBM Redbooks® publication describes how to set up the zEDC functionality to obtain the benefits of portability, reduced storage space, and reduced processor use for large operational sets of data with the most current IBM System z® environment.\n\nPlease note that the additional material referenced in the text is not available from IBM.","tags":["Software Development","Computer Science","Data Compression"]},{"id":"9780072262391","language":"en","level":"Beginner to intermediate","title":"Microsoft SQL Server 2005 Reporting Services, 2nd Edition","authors":["Brian Larson"],"pages":"767","publication_date":"January 2006","description":"Microsoft's Reporting Services product is a vital part of the SQL Server 2005 business intelligence platform, but it works with virtually any data source. This hands-on guide explains how to transform data into insightful and interactive Web-based reports using Microsoft SQL Server 2005 Reporting Services. With coverage of everything from installation to administration, the book demonstrates how to use this powerful server-based reporting solution to improve business decision-making and facilitate company-wide -- even worldwide -- communication.","tags":["Data","Data Engineering","Relational Databases","Microsoft SQL Server"]},{"id":"9781492048169","language":"en","level":"Intermediate to advanced","title":"Data: Emerging Trends and Technologies","authors":["Alistair Croll"],"pages":"25","publication_date":"February 2015","description":"What are the emerging trends and technologies that will transform the data landscape in coming months? In this report from Strata + Hadoop World co-chair Alistair Croll, you'll learn how the ubiquity of cheap sensors, fast networks, and distributed computing have given rise to several developments that will soon have a profound effect on individuals and society as a whole. Machine learning, for example, has quickly moved from lab tool to hosted, pay-as-you-go services in the cloud. Those services, in turn, are leading to predictive apps that will provide individuals with the right functionality and content at the right time by continuously learning about them and predicting what they'll need. Computational power can produce cognitive augmentation.Report topics include:\n\nThe swing between centralized and distributed computing\nMachine learning as a service\nPersonal digital assistants and cognitive augmentation\nGraph databases and analytics\nRegulating complex algorithms\nThe pace of real-time data and automation\nSolving dire problems with big data\nImplications of having sensors everywhere\nThis report contains many more examples of how big data is starting to reshape business and change behavior, and it's just a small sample of the in-depth information Strata + Hadoop World provides. Pick up this report and make plans to attend one of several Strata + Hadoop World conferences in the San Francisco Bay Area, London, and New York.","tags":["Data","Data Engineering"]},{"id":"9781492048510","language":"en","level":"Intermediate to advanced","title":"Ambient Computing","authors":["Mike Barlow"],"pages":"18","publication_date":"June 2016","description":"Consider this scenario: You walk into a building and a sensor identifies you through your mobile phone. You then receive a welcoming text telling you when lunch will be served, or perhaps a health warning based on allergy information you’ve stored in your profile. Maybe you’ll be flagged as a security threat. How is that possible? This O’Reilly report explores ambient computing—hands-free, 24/7 wireless connectivity to hardware, data, and IT systems.\n\nEnabling that scenario requires a lot of work behind the scenes to determine network connectivity, device security, and personal privacy. With an ambient-computing technology stack already in the works, resolving those issues is only a matter of time. Through interviews with front-line tech pioneers—including Ari Gesher (Kairos Aerospace) and Matthew Gast (Aerohive Networks)—author Mike Barlow explores how real-time analytics can enable real-time decision making.\n\nHow will simple beacons broadcast information to your phone as you pass businesses on your morning walk? How can emotional speech analysis monitor the emotional state of employees, students, or people in crowds? Pick up this report and find out.","tags":["Data","Data Engineering","Data Security & Privacy"]},{"id":"53863MIT57213","language":"en","level":"Intermediate to advanced","title":"A New Vision for Personal Transportation","authors":["Wolfgang Gruel","Frank T. Piller","Frank Piller"],"pages":"4","publication_date":"January 2016","description":"The authors argue that applying smart data and the principles of mass customization to transportation ecosystems will enable new business models — and fundamentally change the way we travel.","tags":["Data","Data Engineering","Data Migration"]}]